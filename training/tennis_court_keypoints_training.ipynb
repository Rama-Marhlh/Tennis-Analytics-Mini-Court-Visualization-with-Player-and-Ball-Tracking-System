{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# download from https://github.com/yastrebksv/TennisCourtDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-19 14:00:06--  https://drive.usercontent.google.com/download?id=1lhAaeQCmk2y440PmagA0KmIVBIysVMwu&export=download&authuser=0&confirm=t&uuid=3077628e-fc9b-4ef2-8cde-b291040afb30&at=APZUnTU9lSikCSe3NqbxV5MVad5T%3A1708243355040\n",
      "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 142.250.185.65, 2a00:1450:4001:80e::2001\n",
      "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|142.250.185.65|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7255696316 (6.8G) [application/octet-stream]\n",
      "Saving to: ‘tennis_court_det_dataset.zip’\n",
      "\n",
      "           tennis_c   0%[                    ]  13.80M  17.7KB/s    eta 4d 23h ^C\n"
     ]
    }
   ],
   "source": [
    "!wget --header=\"Host: drive.usercontent.google.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\" --header=\"Accept-Language: en-US,en;q=0.9,ar;q=0.8\" --header=\"Cookie: HSID=Ag2OIHvsd2Wub4C7z; SSID=AWnBcQKwDHiTrZAU1; APISID=pltrFZgE9lJ0o1gq/AN9feEHYvs8oHd519; SAPISID=zgF45F21ZPWzYWZw/AgUMJ8b7QQXuWGn19; __Secure-1PAPISID=zgF45F21ZPWzYWZw/AgUMJ8b7QQXuWGn19; __Secure-3PAPISID=zgF45F21ZPWzYWZw/AgUMJ8b7QQXuWGn19; SID=g.a000fwgYx1PcnW-rFyFhg3x6mQHzCrwXz-KFhoOLogUl7YTWI-uttBbVDRolhF-hY16nwHXw0gACgYKAWISAQASFQHGX2MivNTw_E_toJuIRy6LMpKNOBoVAUF8yKpFSmvq7AMjvEWeNc50Zff40076; __Secure-1PSID=g.a000fwgYx1PcnW-rFyFhg3x6mQHzCrwXz-KFhoOLogUl7YTWI-utbSY2jBY1VXuw8gYl5hIO2QACgYKAXsSAQASFQHGX2MihVCJ1PwLozGqZgdSatM9QhoVAUF8yKpgrsTvI8i_UE-YHpoN7Gx-0076; __Secure-3PSID=g.a000fwgYx1PcnW-rFyFhg3x6mQHzCrwXz-KFhoOLogUl7YTWI-utwVfPl2imdPimZJ9tdDZGQAACgYKAUESAQASFQHGX2MiEJ49mV4jME2kttDAV5hwWBoVAUF8yKp80mIgju1lu-q4nI7VsFDM0076; NID=511=efI9IZpxtyJ7Dw1MAUXU8FlzS5jXGewY4Er8HliWc3A0RSWdgvNDyKY66ETjgRyTGWPbWODSmiSeYSBab5SPHVwqbJxd6ZeGW2f6BkHi61UKksXPH0CVJRM1hKpMjHPU5qw7tboM2Mi87NrosV8COB-GCLulLLbjOoSAEQewTe8NVZ5Owq8IkwvxFGfJkmUKEMkFWrw9yb5nTDl3wbZEsGFI92iEdNTSxSRovNCIPN2US-SCFdQ0m2BtvwdiWZbgnn7dSQ8yPA145Kk2BA-ATpJNJ6SJHEHLQY-9CPail9D5qgJgxR925EUg5RGCpEu9wS5xbA62KTa19wAvbAq7Dk3TWc-iX4p1s7ESFyDC7yMpFxiFPJjqkWwFi_ZfiK2TW2t0TQ60DFBxqOytQaLyHrkEvD-CQPVj6OCOP22cZY0Cu61HaAQgFO9pXH-kJUlywzVdbirJumN5gswyaQ49b3KdLcG0Jb7brOMTM24T2nGtQ10hJzsnTwX7dBk3ujqQrI_DGuURvPassPUrIZ0; AEC=Ae3NU9MOEGeKAZjP6INpOYbyMraWAWztmx5pJB_1ILu1furiTy1K37k15u0; __Secure-1PSIDTS=sidts-CjEBYfD7Z9twEKTWJ9gU7KG-rLbxJGNRQIoG3wH6JVu6yiCC2fsRrm7tN8L6d5WlILrnEAA; __Secure-3PSIDTS=sidts-CjEBYfD7Z9twEKTWJ9gU7KG-rLbxJGNRQIoG3wH6JVu6yiCC2fsRrm7tN8L6d5WlILrnEAA; 1P_JAR=2024-02-18-08; SIDCC=ABTWhQExCxkfmwCkG1RaEgz8U1ZkPeh3HmLMUdMt8S5cNSsLY5U5rAL6wlvq7dtjRw7zrtAbqsFI; __Secure-1PSIDCC=ABTWhQH0jLeRIS6Tu3LS8DXB5Q3gGDq9LTmlk60FKu795Bf0UbzsOcYWVAE96clq5aAL8i724Q0; __Secure-3PSIDCC=ABTWhQHIFcyv3nZYwp78WXEQal71jCE_ZsGT5lXs8VLr7XDIfFqHcLTIPz4HxzJb9ZnYQ5l2s9eU\" --header=\"Connection: keep-alive\" \"https://drive.usercontent.google.com/download?id=1lhAaeQCmk2y440PmagA0KmIVBIysVMwu&export=download&authuser=0&confirm=t&uuid=3077628e-fc9b-4ef2-8cde-b291040afb30&at=APZUnTU9lSikCSe3NqbxV5MVad5T%3A1708243355040\" -c -O 'tennis_court_det_dataset.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip tennis_court_det_dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code describes the process of training a neural network for **keypoint detection** on tennis courts. The goal is to detect specific landmarks or keypoints (e.g., corners or lines) in tennis court images.\n",
    "\n",
    "Here’s an explanation of the code and process:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Dataset Preparation**\n",
    "\n",
    "#### **Dataset Class (`KeypointsDataset`)**\n",
    "This class defines how the data is prepared for the model.\n",
    "\n",
    "- **Initialization (`__init__`)**:\n",
    "  - **`img_dir`**: Directory containing input images.\n",
    "  - **`data_file`**: A JSON file containing the keypoints for each image.\n",
    "    - Example JSON structure:\n",
    "      ```json\n",
    "      [\n",
    "        {\"id\": \"image1\", \"kps\": [x1, y1, x2, y2, ..., x14, y14]},\n",
    "        {\"id\": \"image2\", \"kps\": [x1, y1, x2, y2, ..., x14, y14]}\n",
    "      ]\n",
    "      ```\n",
    "  - **Transformations (`self.transforms`)**:\n",
    "    - Converts the image to a PIL format.\n",
    "    - Resizes the image to a fixed size (`224x224` pixels).\n",
    "    - Converts the image to a PyTorch tensor.\n",
    "    - Normalizes the image using ImageNet’s mean and standard deviation.\n",
    "\n",
    "---\n",
    "\n",
    "- **Dataset Length (`__len__`)**:\n",
    "  Returns the number of images in the dataset.\n",
    "\n",
    "---\n",
    "\n",
    "- **Fetching an Item (`__getitem__`)**:\n",
    "  For a given index `idx`, it:\n",
    "  1. Reads the corresponding image (`.png` format) and keypoints.\n",
    "  2. Converts the image to RGB and resizes it to `224x224`.\n",
    "  3. Adjusts the keypoint coordinates to match the resized image dimensions:\n",
    "     - X-coordinates are scaled by `224.0 / original width`.\n",
    "     - Y-coordinates are scaled by `224.0 / original height`.\n",
    "  4. Returns the transformed image and the adjusted keypoints as:\n",
    "     ```python\n",
    "     return img, kps\n",
    "     ```\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Model Architecture**\n",
    "\n",
    "```python\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 14 * 2)\n",
    "```\n",
    "\n",
    "- **Base Model**:\n",
    "  - Uses `ResNet-50`, a powerful pretrained CNN from PyTorch's `torchvision.models`.\n",
    "  - The pretrained weights come from ImageNet, which provides strong feature extraction capabilities.\n",
    "\n",
    "- **Modified Final Layer**:\n",
    "  - The original `fc` (fully connected) layer is replaced.\n",
    "  - The new layer has an output size of `14 * 2`:\n",
    "    - **14 keypoints**, each with **x and y coordinates**.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Training the Model**\n",
    "\n",
    "```python\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "epochs = 20\n",
    "```\n",
    "\n",
    "#### **Loss Function (`criterion`)**:\n",
    "- **`MSELoss`**: Mean Squared Error loss measures the difference between predicted and actual keypoints. \n",
    "  - Used because keypoint detection is a regression task (continuous values for coordinates).\n",
    "\n",
    "#### **Optimizer (`optimizer`)**:\n",
    "- **`Adam`**: Adaptive optimization algorithm with a learning rate of `1e-4`.\n",
    "\n",
    "#### **Training Loop**:\n",
    "The training loop processes batches of images and keypoints to optimize the model:\n",
    "1. **Input Preparation**:\n",
    "   - Images (`imgs`) and keypoints (`kps`) are fetched from the dataset and moved to the training device (e.g., CPU or GPU).\n",
    "\n",
    "2. **Forward Pass**:\n",
    "   - The images are passed through the model to generate predicted keypoints (`outputs`).\n",
    "\n",
    "3. **Loss Computation**:\n",
    "   - The loss is calculated using `criterion(outputs, kps)`.\n",
    "\n",
    "4. **Backward Pass**:\n",
    "   - Gradients are computed using `loss.backward()`.\n",
    "\n",
    "5. **Optimizer Step**:\n",
    "   - The optimizer updates the model parameters using `optimizer.step()`.\n",
    "\n",
    "6. **Logging**:\n",
    "   - Every 10 iterations, the loss value is printed for monitoring.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Saving the Trained Model**\n",
    "\n",
    "```python\n",
    "torch.save(model.state_dict(), \"keypoints_model.pth\")\n",
    "```\n",
    "\n",
    "- Saves the model's trained parameters to a file (`keypoints_model.pth`).\n",
    "- Can be loaded later for inference or fine-tuning.\n",
    "\n",
    "---\n",
    "\n",
    "### **Process Overview**\n",
    "\n",
    "1. **Dataset Creation**:\n",
    "   - Load tennis court images and their corresponding keypoints from the dataset.\n",
    "   - Transform the images and adjust keypoint coordinates for a fixed size.\n",
    "\n",
    "2. **Model Training**:\n",
    "   - Use a pretrained ResNet-50 model with a custom output layer for keypoint regression.\n",
    "   - Train the model to minimize the difference between predicted and actual keypoints.\n",
    "\n",
    "3. **Model Saving**:\n",
    "   - Save the trained weights to reuse them during inference.\n",
    "\n",
    "---\n",
    "\n",
    "### **Output**\n",
    "After training, the model can:\n",
    "- Predict the keypoints (e.g., court lines, corners) on unseen tennis court images.\n",
    "- The saved model (`keypoints_model.pth`) contains the learned weights for inference tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Torch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeypointsDataset(Dataset):\n",
    "    def __init__(self, img_dir, data_file):\n",
    "        self.img_dir = img_dir\n",
    "        with open(data_file, \"r\") as f:\n",
    "            self.data = json.load(f)\n",
    "        \n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        img = cv2.imread(f\"{self.img_dir}/{item['id']}.png\")\n",
    "        h,w = img.shape[:2]\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = self.transforms(img)\n",
    "        kps = np.array(items['kps']).flatten()\n",
    "        kps = kps.astype(np.float32)\n",
    "\n",
    "        kps[::2] *= 224.0 / w # Adjust x coordinates\n",
    "        kps[1::2] *= 224.0 / h # Adjust y coordinates\n",
    "\n",
    "        return img, kps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeypointsDataset(Dataset):\n",
    "    def __init__(self, img_dir, data_file):\n",
    "        self.img_dir = img_dir\n",
    "        with open(data_file, \"r\") as f:\n",
    "            self.data = json.load(f)\n",
    "        \n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Fetch the current item's data\n",
    "        item = self.data[idx]\n",
    "        \n",
    "        # Load the image\n",
    "        img_path = f\"{self.img_dir}/{item['id']}.png\"\n",
    "        img = cv2.imread(img_path)\n",
    "        h, w = img.shape[:2]\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Apply transformations\n",
    "        img = self.transforms(img)\n",
    "        \n",
    "        # Load and process keypoints\n",
    "        kps = np.array(item['kps']).flatten()\n",
    "        kps = kps.astype(np.float32)\n",
    "\n",
    "        # Adjust keypoint coordinates to match the resized image\n",
    "        kps[::2] *= 224.0 / w  # Adjust x coordinates\n",
    "        kps[1::2] *= 224.0 / h  # Adjust y coordinates\n",
    "\n",
    "        return img, kps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = KeypointsDataset(\"data/images\",\"data/data_train.json\")\n",
    "val_dataset = KeypointsDataset(\"data/images\",\"data/data_val.json\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smartcube/PyCaret/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/smartcube/PyCaret/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /home/smartcube/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████████████████████████████████████████████████| 97.8M/97.8M [00:53<00:00, 1.93MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "model.fc =  torch.nn.Linear(model.fc.in_features, 14*2) # Replaces the last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, iter 0, loss: 14468.212890625\n",
      "Epoch 0, iter 10, loss: 16335.5234375\n",
      "Epoch 0, iter 20, loss: 14475.5751953125\n",
      "Epoch 0, iter 30, loss: 13853.90625\n",
      "Epoch 0, iter 40, loss: 13491.5673828125\n",
      "Epoch 0, iter 50, loss: 13450.611328125\n",
      "Epoch 0, iter 60, loss: 12431.849609375\n",
      "Epoch 0, iter 70, loss: 11923.7041015625\n",
      "Epoch 0, iter 80, loss: 11770.814453125\n",
      "Epoch 0, iter 90, loss: 11883.5556640625\n",
      "Epoch 0, iter 100, loss: 11255.8583984375\n",
      "Epoch 0, iter 110, loss: 11101.853515625\n",
      "Epoch 0, iter 120, loss: 10389.994140625\n",
      "Epoch 0, iter 130, loss: 10804.607421875\n",
      "Epoch 0, iter 140, loss: 9692.7890625\n",
      "Epoch 0, iter 150, loss: 9031.927734375\n",
      "Epoch 0, iter 160, loss: 8844.0830078125\n",
      "Epoch 0, iter 170, loss: 8500.220703125\n",
      "Epoch 0, iter 180, loss: 8265.076171875\n",
      "Epoch 0, iter 190, loss: 8425.619140625\n",
      "Epoch 0, iter 200, loss: 7219.42822265625\n",
      "Epoch 0, iter 210, loss: 7481.66552734375\n",
      "Epoch 0, iter 220, loss: 6423.4150390625\n",
      "Epoch 0, iter 230, loss: 7035.86865234375\n",
      "Epoch 0, iter 240, loss: 7304.71142578125\n",
      "Epoch 0, iter 250, loss: 6508.23486328125\n",
      "Epoch 0, iter 260, loss: 5608.0078125\n",
      "Epoch 0, iter 270, loss: 6045.14599609375\n",
      "Epoch 0, iter 280, loss: 5467.84814453125\n",
      "Epoch 0, iter 290, loss: 5198.8974609375\n",
      "Epoch 0, iter 300, loss: 4835.8388671875\n",
      "Epoch 0, iter 310, loss: 5727.48828125\n",
      "Epoch 0, iter 320, loss: 4708.0908203125\n",
      "Epoch 0, iter 330, loss: 4629.33349609375\n",
      "Epoch 0, iter 340, loss: 4597.99609375\n",
      "Epoch 0, iter 350, loss: 4558.35986328125\n",
      "Epoch 0, iter 360, loss: 3906.59423828125\n",
      "Epoch 0, iter 370, loss: 3715.725341796875\n",
      "Epoch 0, iter 380, loss: 3529.265625\n",
      "Epoch 0, iter 390, loss: 3300.164794921875\n",
      "Epoch 0, iter 400, loss: 3342.123291015625\n",
      "Epoch 0, iter 410, loss: 3183.748291015625\n",
      "Epoch 0, iter 420, loss: 3138.618896484375\n",
      "Epoch 0, iter 430, loss: 2895.102294921875\n",
      "Epoch 0, iter 440, loss: 2802.033935546875\n",
      "Epoch 0, iter 450, loss: 2673.61083984375\n",
      "Epoch 0, iter 460, loss: 2465.323486328125\n",
      "Epoch 0, iter 470, loss: 2307.94140625\n",
      "Epoch 0, iter 480, loss: 2126.138427734375\n",
      "Epoch 0, iter 490, loss: 2165.254150390625\n",
      "Epoch 0, iter 500, loss: 2133.72314453125\n",
      "Epoch 0, iter 510, loss: 1867.9222412109375\n",
      "Epoch 0, iter 520, loss: 1732.8565673828125\n",
      "Epoch 0, iter 530, loss: 1601.8363037109375\n",
      "Epoch 0, iter 540, loss: 1446.4112548828125\n",
      "Epoch 0, iter 550, loss: 1439.8961181640625\n",
      "Epoch 0, iter 560, loss: 1637.375244140625\n",
      "Epoch 0, iter 570, loss: 1496.638916015625\n",
      "Epoch 0, iter 580, loss: 1398.796875\n",
      "Epoch 0, iter 590, loss: 1084.2193603515625\n",
      "Epoch 0, iter 600, loss: 1024.514404296875\n",
      "Epoch 0, iter 610, loss: 1194.9647216796875\n",
      "Epoch 0, iter 620, loss: 975.5126342773438\n",
      "Epoch 0, iter 630, loss: 1032.9993896484375\n",
      "Epoch 0, iter 640, loss: 833.44287109375\n",
      "Epoch 0, iter 650, loss: 807.9024047851562\n",
      "Epoch 0, iter 660, loss: 753.9180297851562\n",
      "Epoch 0, iter 670, loss: 689.32666015625\n",
      "Epoch 0, iter 680, loss: 716.38330078125\n",
      "Epoch 0, iter 690, loss: 721.2047729492188\n",
      "Epoch 0, iter 700, loss: 656.5513305664062\n",
      "Epoch 0, iter 710, loss: 560.71826171875\n",
      "Epoch 0, iter 720, loss: 459.5579528808594\n",
      "Epoch 0, iter 730, loss: 445.83404541015625\n",
      "Epoch 0, iter 740, loss: 423.6000061035156\n",
      "Epoch 0, iter 750, loss: 461.3083190917969\n",
      "Epoch 0, iter 760, loss: 1037.3531494140625\n",
      "Epoch 0, iter 770, loss: 362.4815979003906\n",
      "Epoch 0, iter 780, loss: 327.863037109375\n",
      "Epoch 0, iter 790, loss: 312.8260803222656\n",
      "Epoch 0, iter 800, loss: 323.98919677734375\n",
      "Epoch 0, iter 810, loss: 460.97119140625\n",
      "Epoch 0, iter 820, loss: 254.31130981445312\n",
      "Epoch 1, iter 0, loss: 218.9416046142578\n",
      "Epoch 1, iter 10, loss: 381.87896728515625\n",
      "Epoch 1, iter 20, loss: 191.5340576171875\n",
      "Epoch 1, iter 30, loss: 184.2563018798828\n",
      "Epoch 1, iter 40, loss: 154.68994140625\n",
      "Epoch 1, iter 50, loss: 329.5586853027344\n",
      "Epoch 1, iter 60, loss: 139.43788146972656\n",
      "Epoch 1, iter 70, loss: 131.17041015625\n",
      "Epoch 1, iter 80, loss: 119.77910614013672\n",
      "Epoch 1, iter 90, loss: 114.41146087646484\n",
      "Epoch 1, iter 100, loss: 152.0904083251953\n",
      "Epoch 1, iter 110, loss: 124.19062042236328\n",
      "Epoch 1, iter 120, loss: 110.4570083618164\n",
      "Epoch 1, iter 130, loss: 106.90614318847656\n",
      "Epoch 1, iter 140, loss: 99.56727600097656\n",
      "Epoch 1, iter 150, loss: 144.37356567382812\n",
      "Epoch 1, iter 160, loss: 74.6364974975586\n",
      "Epoch 1, iter 170, loss: 128.82217407226562\n",
      "Epoch 1, iter 180, loss: 77.58426666259766\n",
      "Epoch 1, iter 190, loss: 89.05540466308594\n",
      "Epoch 1, iter 200, loss: 98.82148742675781\n",
      "Epoch 1, iter 210, loss: 73.13359069824219\n",
      "Epoch 1, iter 220, loss: 130.24395751953125\n",
      "Epoch 1, iter 230, loss: 82.1556396484375\n",
      "Epoch 1, iter 240, loss: 68.1618881225586\n",
      "Epoch 1, iter 250, loss: 51.353309631347656\n",
      "Epoch 1, iter 260, loss: 61.92744827270508\n",
      "Epoch 1, iter 270, loss: 99.76732635498047\n",
      "Epoch 1, iter 280, loss: 47.37367630004883\n",
      "Epoch 1, iter 290, loss: 51.89612579345703\n",
      "Epoch 1, iter 300, loss: 62.381126403808594\n",
      "Epoch 1, iter 310, loss: 44.700408935546875\n",
      "Epoch 1, iter 320, loss: 43.449398040771484\n",
      "Epoch 1, iter 330, loss: 66.45977783203125\n",
      "Epoch 1, iter 340, loss: 31.814926147460938\n",
      "Epoch 1, iter 350, loss: 49.816612243652344\n",
      "Epoch 1, iter 360, loss: 39.62105178833008\n",
      "Epoch 1, iter 370, loss: 39.105403900146484\n",
      "Epoch 1, iter 380, loss: 76.32747650146484\n",
      "Epoch 1, iter 390, loss: 81.61161804199219\n",
      "Epoch 1, iter 400, loss: 79.51249694824219\n",
      "Epoch 1, iter 410, loss: 68.54821014404297\n",
      "Epoch 1, iter 420, loss: 36.63920211791992\n",
      "Epoch 1, iter 430, loss: 40.55384063720703\n",
      "Epoch 1, iter 440, loss: 44.94347381591797\n",
      "Epoch 1, iter 450, loss: 157.4659423828125\n",
      "Epoch 1, iter 460, loss: 43.000885009765625\n",
      "Epoch 1, iter 470, loss: 61.151649475097656\n",
      "Epoch 1, iter 480, loss: 40.0256233215332\n",
      "Epoch 1, iter 490, loss: 55.95562744140625\n",
      "Epoch 1, iter 500, loss: 156.50045776367188\n",
      "Epoch 1, iter 510, loss: 63.668758392333984\n",
      "Epoch 1, iter 520, loss: 58.72394561767578\n",
      "Epoch 1, iter 530, loss: 194.1556396484375\n",
      "Epoch 1, iter 540, loss: 42.25568389892578\n",
      "Epoch 1, iter 550, loss: 32.404327392578125\n",
      "Epoch 1, iter 560, loss: 54.30758285522461\n",
      "Epoch 1, iter 570, loss: 62.15789031982422\n",
      "Epoch 1, iter 580, loss: 23.074289321899414\n",
      "Epoch 1, iter 590, loss: 40.339324951171875\n",
      "Epoch 1, iter 600, loss: 52.39883041381836\n",
      "Epoch 1, iter 610, loss: 28.886428833007812\n",
      "Epoch 1, iter 620, loss: 38.746795654296875\n",
      "Epoch 1, iter 630, loss: 35.65424728393555\n",
      "Epoch 1, iter 640, loss: 722.5250854492188\n",
      "Epoch 1, iter 650, loss: 73.67107391357422\n",
      "Epoch 1, iter 660, loss: 25.684188842773438\n",
      "Epoch 1, iter 670, loss: 66.71393585205078\n",
      "Epoch 1, iter 680, loss: 66.86432647705078\n",
      "Epoch 1, iter 690, loss: 66.32958984375\n",
      "Epoch 1, iter 700, loss: 23.98405647277832\n",
      "Epoch 1, iter 710, loss: 49.14850616455078\n",
      "Epoch 1, iter 720, loss: 27.794979095458984\n",
      "Epoch 1, iter 730, loss: 82.28107452392578\n",
      "Epoch 1, iter 740, loss: 25.03592300415039\n",
      "Epoch 1, iter 750, loss: 287.6408996582031\n",
      "Epoch 1, iter 760, loss: 33.50323486328125\n",
      "Epoch 1, iter 770, loss: 54.698307037353516\n",
      "Epoch 1, iter 780, loss: 23.02741050720215\n",
      "Epoch 1, iter 790, loss: 17.269071578979492\n",
      "Epoch 1, iter 800, loss: 162.7011260986328\n",
      "Epoch 1, iter 810, loss: 53.7873649597168\n",
      "Epoch 1, iter 820, loss: 74.29216003417969\n",
      "Epoch 2, iter 0, loss: 27.497148513793945\n",
      "Epoch 2, iter 10, loss: 41.774471282958984\n",
      "Epoch 2, iter 20, loss: 25.236007690429688\n",
      "Epoch 2, iter 30, loss: 21.84147834777832\n",
      "Epoch 2, iter 40, loss: 104.82160186767578\n",
      "Epoch 2, iter 50, loss: 82.11485290527344\n",
      "Epoch 2, iter 60, loss: 22.940744400024414\n",
      "Epoch 2, iter 70, loss: 25.626054763793945\n",
      "Epoch 2, iter 80, loss: 48.605812072753906\n",
      "Epoch 2, iter 90, loss: 80.16966247558594\n",
      "Epoch 2, iter 100, loss: 194.64064025878906\n",
      "Epoch 2, iter 110, loss: 34.562644958496094\n",
      "Epoch 2, iter 120, loss: 31.830289840698242\n",
      "Epoch 2, iter 130, loss: 15.097535133361816\n",
      "Epoch 2, iter 140, loss: 55.36703109741211\n",
      "Epoch 2, iter 150, loss: 30.36240577697754\n",
      "Epoch 2, iter 160, loss: 21.74728012084961\n",
      "Epoch 2, iter 170, loss: 55.58037567138672\n",
      "Epoch 2, iter 180, loss: 23.173542022705078\n",
      "Epoch 2, iter 190, loss: 32.57463455200195\n",
      "Epoch 2, iter 200, loss: 44.421722412109375\n",
      "Epoch 2, iter 210, loss: 67.00768280029297\n",
      "Epoch 2, iter 220, loss: 16.3259220123291\n",
      "Epoch 2, iter 230, loss: 22.15359115600586\n",
      "Epoch 2, iter 240, loss: 42.4659309387207\n",
      "Epoch 2, iter 250, loss: 26.30527114868164\n",
      "Epoch 2, iter 260, loss: 81.62193298339844\n",
      "Epoch 2, iter 270, loss: 32.82194900512695\n",
      "Epoch 2, iter 280, loss: 10.388483047485352\n",
      "Epoch 2, iter 290, loss: 95.75687408447266\n",
      "Epoch 2, iter 300, loss: 25.336288452148438\n",
      "Epoch 2, iter 310, loss: 19.090301513671875\n",
      "Epoch 2, iter 320, loss: 22.039430618286133\n",
      "Epoch 2, iter 330, loss: 14.486039161682129\n",
      "Epoch 2, iter 340, loss: 39.40140151977539\n",
      "Epoch 2, iter 350, loss: 37.0428352355957\n",
      "Epoch 2, iter 360, loss: 32.85171890258789\n",
      "Epoch 2, iter 370, loss: 34.8299674987793\n",
      "Epoch 2, iter 380, loss: 30.60734748840332\n",
      "Epoch 2, iter 390, loss: 10.194239616394043\n",
      "Epoch 2, iter 400, loss: 22.734766006469727\n",
      "Epoch 2, iter 410, loss: 45.69728469848633\n",
      "Epoch 2, iter 420, loss: 19.823774337768555\n",
      "Epoch 2, iter 430, loss: 22.7651309967041\n",
      "Epoch 2, iter 440, loss: 21.3621826171875\n",
      "Epoch 2, iter 450, loss: 31.720613479614258\n",
      "Epoch 2, iter 460, loss: 14.74089527130127\n",
      "Epoch 2, iter 470, loss: 14.45089054107666\n",
      "Epoch 2, iter 480, loss: 32.733123779296875\n",
      "Epoch 2, iter 490, loss: 61.85519027709961\n",
      "Epoch 2, iter 500, loss: 64.47337341308594\n",
      "Epoch 2, iter 510, loss: 147.05088806152344\n",
      "Epoch 2, iter 520, loss: 34.653785705566406\n",
      "Epoch 2, iter 530, loss: 187.94430541992188\n",
      "Epoch 2, iter 540, loss: 23.767826080322266\n",
      "Epoch 2, iter 550, loss: 26.822053909301758\n",
      "Epoch 2, iter 560, loss: 19.842126846313477\n",
      "Epoch 2, iter 570, loss: 35.0722541809082\n",
      "Epoch 2, iter 580, loss: 29.858617782592773\n",
      "Epoch 2, iter 590, loss: 26.665159225463867\n",
      "Epoch 2, iter 600, loss: 27.313446044921875\n",
      "Epoch 2, iter 610, loss: 20.454620361328125\n",
      "Epoch 2, iter 620, loss: 26.288761138916016\n",
      "Epoch 2, iter 630, loss: 15.006080627441406\n",
      "Epoch 2, iter 640, loss: 17.649154663085938\n",
      "Epoch 2, iter 650, loss: 45.3695068359375\n",
      "Epoch 2, iter 660, loss: 25.740571975708008\n",
      "Epoch 2, iter 670, loss: 69.37821197509766\n",
      "Epoch 2, iter 680, loss: 18.43715476989746\n",
      "Epoch 2, iter 690, loss: 26.1397647857666\n",
      "Epoch 2, iter 700, loss: 28.17280387878418\n",
      "Epoch 2, iter 710, loss: 11.894062995910645\n",
      "Epoch 2, iter 720, loss: 48.814579010009766\n",
      "Epoch 2, iter 730, loss: 25.963150024414062\n",
      "Epoch 2, iter 740, loss: 23.9014835357666\n",
      "Epoch 2, iter 750, loss: 24.673051834106445\n",
      "Epoch 2, iter 760, loss: 29.52141761779785\n",
      "Epoch 2, iter 770, loss: 16.986865997314453\n",
      "Epoch 2, iter 780, loss: 143.81192016601562\n",
      "Epoch 2, iter 790, loss: 26.29622459411621\n",
      "Epoch 2, iter 800, loss: 17.238859176635742\n",
      "Epoch 2, iter 810, loss: 15.446803092956543\n",
      "Epoch 2, iter 820, loss: 12.881817817687988\n",
      "Epoch 3, iter 0, loss: 26.378559112548828\n",
      "Epoch 3, iter 10, loss: 121.75836181640625\n",
      "Epoch 3, iter 20, loss: 29.45261573791504\n",
      "Epoch 3, iter 30, loss: 33.18988800048828\n",
      "Epoch 3, iter 40, loss: 27.832820892333984\n",
      "Epoch 3, iter 50, loss: 32.729679107666016\n",
      "Epoch 3, iter 60, loss: 33.915218353271484\n",
      "Epoch 3, iter 70, loss: 22.607818603515625\n",
      "Epoch 3, iter 80, loss: 8.045756340026855\n",
      "Epoch 3, iter 90, loss: 15.417081832885742\n",
      "Epoch 3, iter 100, loss: 24.653715133666992\n",
      "Epoch 3, iter 110, loss: 29.929475784301758\n",
      "Epoch 3, iter 120, loss: 73.10875701904297\n",
      "Epoch 3, iter 130, loss: 43.77729415893555\n",
      "Epoch 3, iter 140, loss: 50.00959014892578\n",
      "Epoch 3, iter 150, loss: 19.65987777709961\n",
      "Epoch 3, iter 160, loss: 34.5700569152832\n",
      "Epoch 3, iter 170, loss: 37.6325569152832\n",
      "Epoch 3, iter 180, loss: 29.82050132751465\n",
      "Epoch 3, iter 190, loss: 11.549715042114258\n",
      "Epoch 3, iter 200, loss: 58.68594741821289\n",
      "Epoch 3, iter 210, loss: 14.853775024414062\n",
      "Epoch 3, iter 220, loss: 17.396825790405273\n",
      "Epoch 3, iter 230, loss: 18.835391998291016\n",
      "Epoch 3, iter 240, loss: 12.50743293762207\n",
      "Epoch 3, iter 250, loss: 155.42727661132812\n",
      "Epoch 3, iter 260, loss: 31.388444900512695\n",
      "Epoch 3, iter 270, loss: 21.71612548828125\n",
      "Epoch 3, iter 280, loss: 12.170706748962402\n",
      "Epoch 3, iter 290, loss: 42.0430908203125\n",
      "Epoch 3, iter 300, loss: 26.03653907775879\n",
      "Epoch 3, iter 310, loss: 19.57716178894043\n",
      "Epoch 3, iter 320, loss: 11.131747245788574\n",
      "Epoch 3, iter 330, loss: 17.226253509521484\n",
      "Epoch 3, iter 340, loss: 20.940542221069336\n",
      "Epoch 3, iter 350, loss: 30.77541732788086\n",
      "Epoch 3, iter 360, loss: 21.149499893188477\n",
      "Epoch 3, iter 370, loss: 30.74640464782715\n",
      "Epoch 3, iter 380, loss: 45.812522888183594\n",
      "Epoch 3, iter 390, loss: 22.898548126220703\n",
      "Epoch 3, iter 400, loss: 19.89433479309082\n",
      "Epoch 3, iter 410, loss: 71.89105987548828\n",
      "Epoch 3, iter 420, loss: 27.115583419799805\n",
      "Epoch 3, iter 430, loss: 22.000410079956055\n",
      "Epoch 3, iter 440, loss: 31.616291046142578\n",
      "Epoch 3, iter 450, loss: 63.20798873901367\n",
      "Epoch 3, iter 460, loss: 17.06264877319336\n",
      "Epoch 3, iter 470, loss: 33.319725036621094\n",
      "Epoch 3, iter 480, loss: 12.754206657409668\n",
      "Epoch 3, iter 490, loss: 16.27225685119629\n",
      "Epoch 3, iter 500, loss: 11.508233070373535\n",
      "Epoch 3, iter 510, loss: 7.5702128410339355\n",
      "Epoch 3, iter 520, loss: 11.673639297485352\n",
      "Epoch 3, iter 530, loss: 10.868536949157715\n",
      "Epoch 3, iter 540, loss: 14.177480697631836\n",
      "Epoch 3, iter 550, loss: 24.091638565063477\n",
      "Epoch 3, iter 560, loss: 20.379566192626953\n",
      "Epoch 3, iter 570, loss: 8.223556518554688\n",
      "Epoch 3, iter 580, loss: 31.292285919189453\n",
      "Epoch 3, iter 590, loss: 19.02496337890625\n",
      "Epoch 3, iter 600, loss: 14.599186897277832\n",
      "Epoch 3, iter 610, loss: 18.50324821472168\n",
      "Epoch 3, iter 620, loss: 44.7674446105957\n",
      "Epoch 3, iter 630, loss: 9.389837265014648\n",
      "Epoch 3, iter 640, loss: 10.163044929504395\n",
      "Epoch 3, iter 650, loss: 26.066747665405273\n",
      "Epoch 3, iter 660, loss: 19.968597412109375\n",
      "Epoch 3, iter 670, loss: 7.596863746643066\n",
      "Epoch 3, iter 680, loss: 11.805087089538574\n",
      "Epoch 3, iter 690, loss: 16.289592742919922\n",
      "Epoch 3, iter 700, loss: 13.252650260925293\n",
      "Epoch 3, iter 710, loss: 7.11051607131958\n",
      "Epoch 3, iter 720, loss: 18.742265701293945\n",
      "Epoch 3, iter 730, loss: 14.408982276916504\n",
      "Epoch 3, iter 740, loss: 48.58112716674805\n",
      "Epoch 3, iter 750, loss: 8.163427352905273\n",
      "Epoch 3, iter 760, loss: 12.26446533203125\n",
      "Epoch 3, iter 770, loss: 6.889698505401611\n",
      "Epoch 3, iter 780, loss: 8.870386123657227\n",
      "Epoch 3, iter 790, loss: 28.34610366821289\n",
      "Epoch 3, iter 800, loss: 21.744672775268555\n",
      "Epoch 3, iter 810, loss: 15.110417366027832\n",
      "Epoch 3, iter 820, loss: 36.973960876464844\n",
      "Epoch 4, iter 0, loss: 13.723942756652832\n",
      "Epoch 4, iter 10, loss: 9.800058364868164\n",
      "Epoch 4, iter 20, loss: 27.831920623779297\n",
      "Epoch 4, iter 30, loss: 11.329901695251465\n",
      "Epoch 4, iter 40, loss: 15.940078735351562\n",
      "Epoch 4, iter 50, loss: 12.669976234436035\n",
      "Epoch 4, iter 60, loss: 14.740766525268555\n",
      "Epoch 4, iter 70, loss: 11.197510719299316\n",
      "Epoch 4, iter 80, loss: 9.875365257263184\n",
      "Epoch 4, iter 90, loss: 10.944451332092285\n",
      "Epoch 4, iter 100, loss: 9.17425537109375\n",
      "Epoch 4, iter 110, loss: 11.6040678024292\n",
      "Epoch 4, iter 120, loss: 13.250805854797363\n",
      "Epoch 4, iter 130, loss: 5.606899261474609\n",
      "Epoch 4, iter 140, loss: 20.08258628845215\n",
      "Epoch 4, iter 150, loss: 9.636785507202148\n",
      "Epoch 4, iter 160, loss: 11.17179012298584\n",
      "Epoch 4, iter 170, loss: 102.50389862060547\n",
      "Epoch 4, iter 180, loss: 20.520206451416016\n",
      "Epoch 4, iter 190, loss: 20.70987319946289\n",
      "Epoch 4, iter 200, loss: 6.66878080368042\n",
      "Epoch 4, iter 210, loss: 11.898821830749512\n",
      "Epoch 4, iter 220, loss: 16.91632652282715\n",
      "Epoch 4, iter 230, loss: 5.059316158294678\n",
      "Epoch 4, iter 240, loss: 12.394353866577148\n",
      "Epoch 4, iter 250, loss: 5.594923496246338\n",
      "Epoch 4, iter 260, loss: 17.4858455657959\n",
      "Epoch 4, iter 270, loss: 9.123486518859863\n",
      "Epoch 4, iter 280, loss: 26.2221736907959\n",
      "Epoch 4, iter 290, loss: 6.109124660491943\n",
      "Epoch 4, iter 300, loss: 10.082732200622559\n",
      "Epoch 4, iter 310, loss: 4.923863887786865\n",
      "Epoch 4, iter 320, loss: 25.509033203125\n",
      "Epoch 4, iter 330, loss: 26.857282638549805\n",
      "Epoch 4, iter 340, loss: 6.8127665519714355\n",
      "Epoch 4, iter 350, loss: 8.128002166748047\n",
      "Epoch 4, iter 360, loss: 13.073213577270508\n",
      "Epoch 4, iter 370, loss: 12.554010391235352\n",
      "Epoch 4, iter 380, loss: 22.75288963317871\n",
      "Epoch 4, iter 390, loss: 14.787264823913574\n",
      "Epoch 4, iter 400, loss: 23.168506622314453\n",
      "Epoch 4, iter 410, loss: 4.062351226806641\n",
      "Epoch 4, iter 420, loss: 18.665767669677734\n",
      "Epoch 4, iter 430, loss: 7.76308536529541\n",
      "Epoch 4, iter 440, loss: 10.688737869262695\n",
      "Epoch 4, iter 450, loss: 6.004218578338623\n",
      "Epoch 4, iter 460, loss: 11.480300903320312\n",
      "Epoch 4, iter 470, loss: 29.360321044921875\n",
      "Epoch 4, iter 480, loss: 6.89467191696167\n",
      "Epoch 4, iter 490, loss: 4.230384826660156\n",
      "Epoch 4, iter 500, loss: 5.038623809814453\n",
      "Epoch 4, iter 510, loss: 26.51180076599121\n",
      "Epoch 4, iter 520, loss: 9.089944839477539\n",
      "Epoch 4, iter 530, loss: 7.943210124969482\n",
      "Epoch 4, iter 540, loss: 5.963726997375488\n",
      "Epoch 4, iter 550, loss: 13.275909423828125\n",
      "Epoch 4, iter 560, loss: 6.098540782928467\n",
      "Epoch 4, iter 570, loss: 10.040144920349121\n",
      "Epoch 4, iter 580, loss: 7.462985038757324\n",
      "Epoch 4, iter 590, loss: 19.465484619140625\n",
      "Epoch 4, iter 600, loss: 7.764357566833496\n",
      "Epoch 4, iter 610, loss: 3.8870861530303955\n",
      "Epoch 4, iter 620, loss: 21.098831176757812\n",
      "Epoch 4, iter 630, loss: 13.731110572814941\n",
      "Epoch 4, iter 640, loss: 11.899157524108887\n",
      "Epoch 4, iter 650, loss: 9.785637855529785\n",
      "Epoch 4, iter 660, loss: 4.1118974685668945\n",
      "Epoch 4, iter 670, loss: 11.528093338012695\n",
      "Epoch 4, iter 680, loss: 31.35243797302246\n",
      "Epoch 4, iter 690, loss: 46.14658737182617\n",
      "Epoch 4, iter 700, loss: 14.558296203613281\n",
      "Epoch 4, iter 710, loss: 10.663146018981934\n",
      "Epoch 4, iter 720, loss: 10.174529075622559\n",
      "Epoch 4, iter 730, loss: 3.0808072090148926\n",
      "Epoch 4, iter 740, loss: 7.596700191497803\n",
      "Epoch 4, iter 750, loss: 6.119937896728516\n",
      "Epoch 4, iter 760, loss: 12.125077247619629\n",
      "Epoch 4, iter 770, loss: 14.205053329467773\n",
      "Epoch 4, iter 780, loss: 29.465402603149414\n",
      "Epoch 4, iter 790, loss: 4.471278190612793\n",
      "Epoch 4, iter 800, loss: 7.245501518249512\n",
      "Epoch 4, iter 810, loss: 145.82644653320312\n",
      "Epoch 4, iter 820, loss: 10.004530906677246\n",
      "Epoch 5, iter 0, loss: 3.7179572582244873\n",
      "Epoch 5, iter 10, loss: 6.155407428741455\n",
      "Epoch 5, iter 20, loss: 17.031085968017578\n",
      "Epoch 5, iter 30, loss: 7.0894598960876465\n",
      "Epoch 5, iter 40, loss: 13.247419357299805\n",
      "Epoch 5, iter 50, loss: 6.509151458740234\n",
      "Epoch 5, iter 60, loss: 6.381100177764893\n",
      "Epoch 5, iter 70, loss: 4.832339286804199\n",
      "Epoch 5, iter 80, loss: 7.768084526062012\n",
      "Epoch 5, iter 90, loss: 8.02823543548584\n",
      "Epoch 5, iter 100, loss: 7.6203131675720215\n",
      "Epoch 5, iter 110, loss: 4.171652317047119\n",
      "Epoch 5, iter 120, loss: 6.265588283538818\n",
      "Epoch 5, iter 130, loss: 5.985886096954346\n",
      "Epoch 5, iter 140, loss: 6.514179229736328\n",
      "Epoch 5, iter 150, loss: 1.7995673418045044\n",
      "Epoch 5, iter 160, loss: 12.83361530303955\n",
      "Epoch 5, iter 170, loss: 5.639888763427734\n",
      "Epoch 5, iter 180, loss: 18.008737564086914\n",
      "Epoch 5, iter 190, loss: 85.01375579833984\n",
      "Epoch 5, iter 200, loss: 7.9746928215026855\n",
      "Epoch 5, iter 210, loss: 7.255843639373779\n",
      "Epoch 5, iter 220, loss: 12.352002143859863\n",
      "Epoch 5, iter 230, loss: 6.077941417694092\n",
      "Epoch 5, iter 240, loss: 8.214879035949707\n",
      "Epoch 5, iter 250, loss: 18.306047439575195\n",
      "Epoch 5, iter 260, loss: 5.679317951202393\n",
      "Epoch 5, iter 270, loss: 6.69488000869751\n",
      "Epoch 5, iter 280, loss: 6.54757022857666\n",
      "Epoch 5, iter 290, loss: 5.26456880569458\n",
      "Epoch 5, iter 300, loss: 2.7675747871398926\n",
      "Epoch 5, iter 310, loss: 8.979296684265137\n",
      "Epoch 5, iter 320, loss: 1.91929030418396\n",
      "Epoch 5, iter 330, loss: 2.288062334060669\n",
      "Epoch 5, iter 340, loss: 14.216238021850586\n",
      "Epoch 5, iter 350, loss: 25.4367733001709\n",
      "Epoch 5, iter 360, loss: 3.971524953842163\n",
      "Epoch 5, iter 370, loss: 2.1288998126983643\n",
      "Epoch 5, iter 380, loss: 6.455440521240234\n",
      "Epoch 5, iter 390, loss: 6.654213905334473\n",
      "Epoch 5, iter 400, loss: 9.748900413513184\n",
      "Epoch 5, iter 410, loss: 6.737206935882568\n",
      "Epoch 5, iter 420, loss: 4.078001976013184\n",
      "Epoch 5, iter 430, loss: 22.307222366333008\n",
      "Epoch 5, iter 440, loss: 9.847273826599121\n",
      "Epoch 5, iter 450, loss: 4.056295871734619\n",
      "Epoch 5, iter 460, loss: 11.405691146850586\n",
      "Epoch 5, iter 470, loss: 7.918367862701416\n",
      "Epoch 5, iter 480, loss: 3.9970364570617676\n",
      "Epoch 5, iter 490, loss: 15.959765434265137\n",
      "Epoch 5, iter 500, loss: 4.459658622741699\n",
      "Epoch 5, iter 510, loss: 21.122928619384766\n",
      "Epoch 5, iter 520, loss: 7.882906436920166\n",
      "Epoch 5, iter 530, loss: 3.9951095581054688\n",
      "Epoch 5, iter 540, loss: 5.666931629180908\n",
      "Epoch 5, iter 550, loss: 6.338375568389893\n",
      "Epoch 5, iter 560, loss: 6.347815036773682\n",
      "Epoch 5, iter 570, loss: 6.938417911529541\n",
      "Epoch 5, iter 580, loss: 10.594229698181152\n",
      "Epoch 5, iter 590, loss: 5.706302165985107\n",
      "Epoch 5, iter 600, loss: 10.179984092712402\n",
      "Epoch 5, iter 610, loss: 10.758977890014648\n",
      "Epoch 5, iter 620, loss: 6.022761821746826\n",
      "Epoch 5, iter 630, loss: 5.2861328125\n",
      "Epoch 5, iter 640, loss: 17.6473331451416\n",
      "Epoch 5, iter 650, loss: 16.617931365966797\n",
      "Epoch 5, iter 660, loss: 8.37053394317627\n",
      "Epoch 5, iter 670, loss: 5.859557628631592\n",
      "Epoch 5, iter 680, loss: 6.91536283493042\n",
      "Epoch 5, iter 690, loss: 19.937664031982422\n",
      "Epoch 5, iter 700, loss: 7.918502330780029\n",
      "Epoch 5, iter 710, loss: 9.066301345825195\n",
      "Epoch 5, iter 720, loss: 5.160417079925537\n",
      "Epoch 5, iter 730, loss: 4.154932498931885\n",
      "Epoch 5, iter 740, loss: 7.975870609283447\n",
      "Epoch 5, iter 750, loss: 2.2844274044036865\n",
      "Epoch 5, iter 760, loss: 86.10843658447266\n",
      "Epoch 5, iter 770, loss: 4.819648742675781\n",
      "Epoch 5, iter 780, loss: 7.056197166442871\n",
      "Epoch 5, iter 790, loss: 4.4859724044799805\n",
      "Epoch 5, iter 800, loss: 1.7892067432403564\n",
      "Epoch 5, iter 810, loss: 86.33601379394531\n",
      "Epoch 5, iter 820, loss: 3.403616189956665\n",
      "Epoch 6, iter 0, loss: 4.545001029968262\n",
      "Epoch 6, iter 10, loss: 14.863462448120117\n",
      "Epoch 6, iter 20, loss: 4.036149501800537\n",
      "Epoch 6, iter 30, loss: 10.548727989196777\n",
      "Epoch 6, iter 40, loss: 6.495607852935791\n",
      "Epoch 6, iter 50, loss: 11.715394020080566\n",
      "Epoch 6, iter 60, loss: 15.987784385681152\n",
      "Epoch 6, iter 70, loss: 10.05373477935791\n",
      "Epoch 6, iter 80, loss: 4.767446041107178\n",
      "Epoch 6, iter 90, loss: 10.633151054382324\n",
      "Epoch 6, iter 100, loss: 13.814498901367188\n",
      "Epoch 6, iter 110, loss: 10.049935340881348\n",
      "Epoch 6, iter 120, loss: 126.10523223876953\n",
      "Epoch 6, iter 130, loss: 7.916378974914551\n",
      "Epoch 6, iter 140, loss: 10.90980052947998\n",
      "Epoch 6, iter 150, loss: 9.234565734863281\n",
      "Epoch 6, iter 160, loss: 19.723901748657227\n",
      "Epoch 6, iter 170, loss: 15.253667831420898\n",
      "Epoch 6, iter 180, loss: 3.3055922985076904\n",
      "Epoch 6, iter 190, loss: 3.774913787841797\n",
      "Epoch 6, iter 200, loss: 5.8603057861328125\n",
      "Epoch 6, iter 210, loss: 11.89787769317627\n",
      "Epoch 6, iter 220, loss: 11.658056259155273\n",
      "Epoch 6, iter 230, loss: 6.785764217376709\n",
      "Epoch 6, iter 240, loss: 2.5231971740722656\n",
      "Epoch 6, iter 250, loss: 5.02395486831665\n",
      "Epoch 6, iter 260, loss: 7.315728187561035\n",
      "Epoch 6, iter 270, loss: 2.0134687423706055\n",
      "Epoch 6, iter 280, loss: 7.333597660064697\n",
      "Epoch 6, iter 290, loss: 4.538482189178467\n",
      "Epoch 6, iter 300, loss: 10.20409870147705\n",
      "Epoch 6, iter 310, loss: 12.904962539672852\n",
      "Epoch 6, iter 320, loss: 7.002016544342041\n",
      "Epoch 6, iter 330, loss: 15.669075965881348\n",
      "Epoch 6, iter 340, loss: 2.11928653717041\n",
      "Epoch 6, iter 350, loss: 12.129040718078613\n",
      "Epoch 6, iter 360, loss: 2.8250129222869873\n",
      "Epoch 6, iter 370, loss: 9.477801322937012\n",
      "Epoch 6, iter 380, loss: 5.823398113250732\n",
      "Epoch 6, iter 390, loss: 7.297236919403076\n",
      "Epoch 6, iter 400, loss: 2.413874387741089\n",
      "Epoch 6, iter 410, loss: 8.763428688049316\n",
      "Epoch 6, iter 420, loss: 10.722241401672363\n",
      "Epoch 6, iter 430, loss: 18.058218002319336\n",
      "Epoch 6, iter 440, loss: 1.9123632907867432\n",
      "Epoch 6, iter 450, loss: 5.145740032196045\n",
      "Epoch 6, iter 460, loss: 11.097941398620605\n",
      "Epoch 6, iter 470, loss: 10.677780151367188\n",
      "Epoch 6, iter 480, loss: 2.4787228107452393\n",
      "Epoch 6, iter 490, loss: 15.218804359436035\n",
      "Epoch 6, iter 500, loss: 31.189531326293945\n",
      "Epoch 6, iter 510, loss: 3.6224918365478516\n",
      "Epoch 6, iter 520, loss: 4.337410926818848\n",
      "Epoch 6, iter 530, loss: 11.21531867980957\n",
      "Epoch 6, iter 540, loss: 10.816521644592285\n",
      "Epoch 6, iter 550, loss: 6.532893657684326\n",
      "Epoch 6, iter 560, loss: 92.47950744628906\n",
      "Epoch 6, iter 570, loss: 6.703515529632568\n",
      "Epoch 6, iter 580, loss: 10.91036319732666\n",
      "Epoch 6, iter 590, loss: 13.920599937438965\n",
      "Epoch 6, iter 600, loss: 11.853407859802246\n",
      "Epoch 6, iter 610, loss: 6.994571685791016\n",
      "Epoch 6, iter 620, loss: 3.8142261505126953\n",
      "Epoch 6, iter 630, loss: 3.0043258666992188\n",
      "Epoch 6, iter 640, loss: 4.944070339202881\n",
      "Epoch 6, iter 650, loss: 9.963836669921875\n",
      "Epoch 6, iter 660, loss: 7.718371868133545\n",
      "Epoch 6, iter 670, loss: 10.54662036895752\n",
      "Epoch 6, iter 680, loss: 6.025360107421875\n",
      "Epoch 6, iter 690, loss: 3.9356296062469482\n",
      "Epoch 6, iter 700, loss: 5.946316719055176\n",
      "Epoch 6, iter 710, loss: 9.699776649475098\n",
      "Epoch 6, iter 720, loss: 14.008740425109863\n",
      "Epoch 6, iter 730, loss: 3.6584696769714355\n",
      "Epoch 6, iter 740, loss: 7.094235897064209\n",
      "Epoch 6, iter 750, loss: 3.078629732131958\n",
      "Epoch 6, iter 760, loss: 2.6458678245544434\n",
      "Epoch 6, iter 770, loss: 31.066442489624023\n",
      "Epoch 6, iter 780, loss: 9.584929466247559\n",
      "Epoch 6, iter 790, loss: 3.2298851013183594\n",
      "Epoch 6, iter 800, loss: 16.39995765686035\n",
      "Epoch 6, iter 810, loss: 13.604369163513184\n",
      "Epoch 6, iter 820, loss: 3.0869975090026855\n",
      "Epoch 7, iter 0, loss: 3.2087807655334473\n",
      "Epoch 7, iter 10, loss: 2.4453837871551514\n",
      "Epoch 7, iter 20, loss: 1.9533889293670654\n",
      "Epoch 7, iter 30, loss: 4.636742115020752\n",
      "Epoch 7, iter 40, loss: 2.589655637741089\n",
      "Epoch 7, iter 50, loss: 3.050588369369507\n",
      "Epoch 7, iter 60, loss: 11.398871421813965\n",
      "Epoch 7, iter 70, loss: 4.034071922302246\n",
      "Epoch 7, iter 80, loss: 9.751396179199219\n",
      "Epoch 7, iter 90, loss: 12.824095726013184\n",
      "Epoch 7, iter 100, loss: 6.728118896484375\n",
      "Epoch 7, iter 110, loss: 21.63089942932129\n",
      "Epoch 7, iter 120, loss: 3.224045991897583\n",
      "Epoch 7, iter 130, loss: 13.04716968536377\n",
      "Epoch 7, iter 140, loss: 19.614639282226562\n",
      "Epoch 7, iter 150, loss: 4.655285358428955\n",
      "Epoch 7, iter 160, loss: 6.543295383453369\n",
      "Epoch 7, iter 170, loss: 13.721951484680176\n",
      "Epoch 7, iter 180, loss: 9.448906898498535\n",
      "Epoch 7, iter 190, loss: 3.015158176422119\n",
      "Epoch 7, iter 200, loss: 7.11496114730835\n",
      "Epoch 7, iter 210, loss: 10.864680290222168\n",
      "Epoch 7, iter 220, loss: 3.1209137439727783\n",
      "Epoch 7, iter 230, loss: 2.555704355239868\n",
      "Epoch 7, iter 240, loss: 3.5281643867492676\n",
      "Epoch 7, iter 250, loss: 10.558197975158691\n",
      "Epoch 7, iter 260, loss: 3.958247661590576\n",
      "Epoch 7, iter 270, loss: 1.0774405002593994\n",
      "Epoch 7, iter 280, loss: 4.300847053527832\n",
      "Epoch 7, iter 290, loss: 2.933610677719116\n",
      "Epoch 7, iter 300, loss: 1.7295340299606323\n",
      "Epoch 7, iter 310, loss: 4.390300273895264\n",
      "Epoch 7, iter 320, loss: 1.0511587858200073\n",
      "Epoch 7, iter 330, loss: 24.047550201416016\n",
      "Epoch 7, iter 340, loss: 2.7857067584991455\n",
      "Epoch 7, iter 350, loss: 1.7927443981170654\n",
      "Epoch 7, iter 360, loss: 2.6969640254974365\n",
      "Epoch 7, iter 370, loss: 2.3979623317718506\n",
      "Epoch 7, iter 380, loss: 3.9375064373016357\n",
      "Epoch 7, iter 390, loss: 9.329595565795898\n",
      "Epoch 7, iter 400, loss: 3.533376455307007\n",
      "Epoch 7, iter 410, loss: 2.5207574367523193\n",
      "Epoch 7, iter 420, loss: 10.624343872070312\n",
      "Epoch 7, iter 430, loss: 3.222649335861206\n",
      "Epoch 7, iter 440, loss: 3.4985270500183105\n",
      "Epoch 7, iter 450, loss: 1.5033438205718994\n",
      "Epoch 7, iter 460, loss: 0.8060769438743591\n",
      "Epoch 7, iter 470, loss: 76.28997039794922\n",
      "Epoch 7, iter 480, loss: 8.741129875183105\n",
      "Epoch 7, iter 490, loss: 10.179158210754395\n",
      "Epoch 7, iter 500, loss: 6.7331109046936035\n",
      "Epoch 7, iter 510, loss: 2.045287609100342\n",
      "Epoch 7, iter 520, loss: 10.05942440032959\n",
      "Epoch 7, iter 530, loss: 1.709436058998108\n",
      "Epoch 7, iter 540, loss: 8.918828964233398\n",
      "Epoch 7, iter 550, loss: 1.4817496538162231\n",
      "Epoch 7, iter 560, loss: 0.86004638671875\n",
      "Epoch 7, iter 570, loss: 12.037096977233887\n",
      "Epoch 7, iter 580, loss: 3.233091115951538\n",
      "Epoch 7, iter 590, loss: 8.032588958740234\n",
      "Epoch 7, iter 600, loss: 3.5250935554504395\n",
      "Epoch 7, iter 610, loss: 2.603395938873291\n",
      "Epoch 7, iter 620, loss: 1.6112935543060303\n",
      "Epoch 7, iter 630, loss: 15.519479751586914\n",
      "Epoch 7, iter 640, loss: 1.6899757385253906\n",
      "Epoch 7, iter 650, loss: 5.815399169921875\n",
      "Epoch 7, iter 660, loss: 2.419018507003784\n",
      "Epoch 7, iter 670, loss: 3.3656375408172607\n",
      "Epoch 7, iter 680, loss: 0.7160605192184448\n",
      "Epoch 7, iter 690, loss: 6.07393217086792\n",
      "Epoch 7, iter 700, loss: 11.86872673034668\n",
      "Epoch 7, iter 710, loss: 2.195211410522461\n",
      "Epoch 7, iter 720, loss: 2.019031286239624\n",
      "Epoch 7, iter 730, loss: 2.0077219009399414\n",
      "Epoch 7, iter 740, loss: 2.1749584674835205\n",
      "Epoch 7, iter 750, loss: 1.8862484693527222\n",
      "Epoch 7, iter 760, loss: 1.841216802597046\n",
      "Epoch 7, iter 770, loss: 3.162416458129883\n",
      "Epoch 7, iter 780, loss: 2.574712038040161\n",
      "Epoch 7, iter 790, loss: 2.5280845165252686\n",
      "Epoch 7, iter 800, loss: 2.301445245742798\n",
      "Epoch 7, iter 810, loss: 1.4547173976898193\n",
      "Epoch 7, iter 820, loss: 3.0495598316192627\n",
      "Epoch 8, iter 0, loss: 2.661468267440796\n",
      "Epoch 8, iter 10, loss: 2.903759002685547\n",
      "Epoch 8, iter 20, loss: 3.2509634494781494\n",
      "Epoch 8, iter 30, loss: 25.533632278442383\n",
      "Epoch 8, iter 40, loss: 0.6282473802566528\n",
      "Epoch 8, iter 50, loss: 2.043409824371338\n",
      "Epoch 8, iter 60, loss: 11.113600730895996\n",
      "Epoch 8, iter 70, loss: 2.0567259788513184\n",
      "Epoch 8, iter 80, loss: 14.440003395080566\n",
      "Epoch 8, iter 90, loss: 1.8127119541168213\n",
      "Epoch 8, iter 100, loss: 3.0048043727874756\n",
      "Epoch 8, iter 110, loss: 73.9452133178711\n",
      "Epoch 8, iter 120, loss: 4.576050758361816\n",
      "Epoch 8, iter 130, loss: 4.605868339538574\n",
      "Epoch 8, iter 140, loss: 4.131446361541748\n",
      "Epoch 8, iter 150, loss: 6.169466495513916\n",
      "Epoch 8, iter 160, loss: 3.119781017303467\n",
      "Epoch 8, iter 170, loss: 2.356900930404663\n",
      "Epoch 8, iter 180, loss: 3.222857713699341\n",
      "Epoch 8, iter 190, loss: 7.240931510925293\n",
      "Epoch 8, iter 200, loss: 2.796848773956299\n",
      "Epoch 8, iter 210, loss: 4.159041881561279\n",
      "Epoch 8, iter 220, loss: 3.1982052326202393\n",
      "Epoch 8, iter 230, loss: 3.1595358848571777\n",
      "Epoch 8, iter 240, loss: 5.2264084815979\n",
      "Epoch 8, iter 250, loss: 45.52437210083008\n",
      "Epoch 8, iter 260, loss: 8.716625213623047\n",
      "Epoch 8, iter 270, loss: 9.072288513183594\n",
      "Epoch 8, iter 280, loss: 12.447158813476562\n",
      "Epoch 8, iter 290, loss: 9.830217361450195\n",
      "Epoch 8, iter 300, loss: 3.0323848724365234\n",
      "Epoch 8, iter 310, loss: 1.5021196603775024\n",
      "Epoch 8, iter 320, loss: 2.63608980178833\n",
      "Epoch 8, iter 330, loss: 2.0373237133026123\n",
      "Epoch 8, iter 340, loss: 10.956196784973145\n",
      "Epoch 8, iter 350, loss: 1.3211575746536255\n",
      "Epoch 8, iter 360, loss: 1.6220922470092773\n",
      "Epoch 8, iter 370, loss: 10.486794471740723\n",
      "Epoch 8, iter 380, loss: 3.3768157958984375\n",
      "Epoch 8, iter 390, loss: 5.831962585449219\n",
      "Epoch 8, iter 400, loss: 3.1975529193878174\n",
      "Epoch 8, iter 410, loss: 11.436661720275879\n",
      "Epoch 8, iter 420, loss: 5.321452617645264\n",
      "Epoch 8, iter 430, loss: 2.4710748195648193\n",
      "Epoch 8, iter 440, loss: 5.385871410369873\n",
      "Epoch 8, iter 450, loss: 11.766424179077148\n",
      "Epoch 8, iter 460, loss: 1.8817565441131592\n",
      "Epoch 8, iter 470, loss: 3.2083306312561035\n",
      "Epoch 8, iter 480, loss: 4.834754943847656\n",
      "Epoch 8, iter 490, loss: 2.2516751289367676\n",
      "Epoch 8, iter 500, loss: 4.730071067810059\n",
      "Epoch 8, iter 510, loss: 3.3601796627044678\n",
      "Epoch 8, iter 520, loss: 1.2739564180374146\n",
      "Epoch 8, iter 530, loss: 3.6130659580230713\n",
      "Epoch 8, iter 540, loss: 3.8246405124664307\n",
      "Epoch 8, iter 550, loss: 5.3325724601745605\n",
      "Epoch 8, iter 560, loss: 0.9013692736625671\n",
      "Epoch 8, iter 570, loss: 1.977182388305664\n",
      "Epoch 8, iter 580, loss: 2.31750750541687\n",
      "Epoch 8, iter 590, loss: 2.117506742477417\n",
      "Epoch 8, iter 600, loss: 5.929625511169434\n",
      "Epoch 8, iter 610, loss: 1.4327243566513062\n",
      "Epoch 8, iter 620, loss: 1.5635632276535034\n",
      "Epoch 8, iter 630, loss: 1.74535071849823\n",
      "Epoch 8, iter 640, loss: 0.6913632750511169\n",
      "Epoch 8, iter 650, loss: 4.934509754180908\n",
      "Epoch 8, iter 660, loss: 3.335170030593872\n",
      "Epoch 8, iter 670, loss: 3.518441677093506\n",
      "Epoch 8, iter 680, loss: 7.637777805328369\n",
      "Epoch 8, iter 690, loss: 3.4418880939483643\n",
      "Epoch 8, iter 700, loss: 108.04479217529297\n",
      "Epoch 8, iter 710, loss: 65.8929672241211\n",
      "Epoch 8, iter 720, loss: 3.95470929145813\n",
      "Epoch 8, iter 730, loss: 8.894514083862305\n",
      "Epoch 8, iter 740, loss: 2.5311267375946045\n",
      "Epoch 8, iter 750, loss: 2.375513792037964\n",
      "Epoch 8, iter 760, loss: 4.7168288230896\n",
      "Epoch 8, iter 770, loss: 1.6496742963790894\n",
      "Epoch 8, iter 780, loss: 5.690291881561279\n",
      "Epoch 8, iter 790, loss: 2.996051549911499\n",
      "Epoch 8, iter 800, loss: 6.545659065246582\n",
      "Epoch 8, iter 810, loss: 4.34310245513916\n",
      "Epoch 8, iter 820, loss: 0.9924734830856323\n",
      "Epoch 9, iter 0, loss: 2.3392653465270996\n",
      "Epoch 9, iter 10, loss: 9.296757698059082\n",
      "Epoch 9, iter 20, loss: 9.934270858764648\n",
      "Epoch 9, iter 30, loss: 5.015174865722656\n",
      "Epoch 9, iter 40, loss: 0.9026886820793152\n",
      "Epoch 9, iter 50, loss: 4.635123252868652\n",
      "Epoch 9, iter 60, loss: 2.2668116092681885\n",
      "Epoch 9, iter 70, loss: 2.832347869873047\n",
      "Epoch 9, iter 80, loss: 2.310063600540161\n",
      "Epoch 9, iter 90, loss: 1.2989288568496704\n",
      "Epoch 9, iter 100, loss: 3.049645185470581\n",
      "Epoch 9, iter 110, loss: 1.5901097059249878\n",
      "Epoch 9, iter 120, loss: 1.5219107866287231\n",
      "Epoch 9, iter 130, loss: 3.257420301437378\n",
      "Epoch 9, iter 140, loss: 3.4656484127044678\n",
      "Epoch 9, iter 150, loss: 32.5915641784668\n",
      "Epoch 9, iter 160, loss: 2.2823426723480225\n",
      "Epoch 9, iter 170, loss: 4.050369739532471\n",
      "Epoch 9, iter 180, loss: 2.9663643836975098\n",
      "Epoch 9, iter 190, loss: 11.246847152709961\n",
      "Epoch 9, iter 200, loss: 7.8061747550964355\n",
      "Epoch 9, iter 210, loss: 4.014386177062988\n",
      "Epoch 9, iter 220, loss: 4.57989501953125\n",
      "Epoch 9, iter 230, loss: 3.3459084033966064\n",
      "Epoch 9, iter 240, loss: 118.64615631103516\n",
      "Epoch 9, iter 250, loss: 5.485689640045166\n",
      "Epoch 9, iter 260, loss: 2.3587968349456787\n",
      "Epoch 9, iter 270, loss: 1.9875444173812866\n",
      "Epoch 9, iter 280, loss: 52.70974349975586\n",
      "Epoch 9, iter 290, loss: 2.843240976333618\n",
      "Epoch 9, iter 300, loss: 2.012983560562134\n",
      "Epoch 9, iter 310, loss: 1.8112488985061646\n",
      "Epoch 9, iter 320, loss: 4.675228595733643\n",
      "Epoch 9, iter 330, loss: 2.6248767375946045\n",
      "Epoch 9, iter 340, loss: 1.849717378616333\n",
      "Epoch 9, iter 350, loss: 77.717041015625\n",
      "Epoch 9, iter 360, loss: 1.0269559621810913\n",
      "Epoch 9, iter 370, loss: 5.592434406280518\n",
      "Epoch 9, iter 380, loss: 1.5705749988555908\n",
      "Epoch 9, iter 390, loss: 2.8842902183532715\n",
      "Epoch 9, iter 400, loss: 2.1991994380950928\n",
      "Epoch 9, iter 410, loss: 3.333251953125\n",
      "Epoch 9, iter 420, loss: 2.4015696048736572\n",
      "Epoch 9, iter 430, loss: 7.035410404205322\n",
      "Epoch 9, iter 440, loss: 2.610481023788452\n",
      "Epoch 9, iter 450, loss: 0.8863962292671204\n",
      "Epoch 9, iter 460, loss: 2.7355079650878906\n",
      "Epoch 9, iter 470, loss: 3.8146297931671143\n",
      "Epoch 9, iter 480, loss: 0.9464255571365356\n",
      "Epoch 9, iter 490, loss: 2.6205828189849854\n",
      "Epoch 9, iter 500, loss: 2.686695098876953\n",
      "Epoch 9, iter 510, loss: 3.760979175567627\n",
      "Epoch 9, iter 520, loss: 1.0774638652801514\n",
      "Epoch 9, iter 530, loss: 1.4780762195587158\n",
      "Epoch 9, iter 540, loss: 1.9708783626556396\n",
      "Epoch 9, iter 550, loss: 307.87603759765625\n",
      "Epoch 9, iter 560, loss: 1.8611047267913818\n",
      "Epoch 9, iter 570, loss: 1.529103398323059\n",
      "Epoch 9, iter 580, loss: 1.0014705657958984\n",
      "Epoch 9, iter 590, loss: 4.203636646270752\n",
      "Epoch 9, iter 600, loss: 18.519319534301758\n",
      "Epoch 9, iter 610, loss: 13.520764350891113\n",
      "Epoch 9, iter 620, loss: 1.4512856006622314\n",
      "Epoch 9, iter 630, loss: 4.711461544036865\n",
      "Epoch 9, iter 640, loss: 2.291962146759033\n",
      "Epoch 9, iter 650, loss: 40.367393493652344\n",
      "Epoch 9, iter 660, loss: 2.4472100734710693\n",
      "Epoch 9, iter 670, loss: 4.482287883758545\n",
      "Epoch 9, iter 680, loss: 8.135641098022461\n",
      "Epoch 9, iter 690, loss: 2.1879489421844482\n",
      "Epoch 9, iter 700, loss: 2.173875093460083\n",
      "Epoch 9, iter 710, loss: 4.132554531097412\n",
      "Epoch 9, iter 720, loss: 4.971371173858643\n",
      "Epoch 9, iter 730, loss: 4.630675315856934\n",
      "Epoch 9, iter 740, loss: 9.811856269836426\n",
      "Epoch 9, iter 750, loss: 2.013657331466675\n",
      "Epoch 9, iter 760, loss: 6.139439105987549\n",
      "Epoch 9, iter 770, loss: 3.3750922679901123\n",
      "Epoch 9, iter 780, loss: 1.9961522817611694\n",
      "Epoch 9, iter 790, loss: 2.1756064891815186\n",
      "Epoch 9, iter 800, loss: 7.759697914123535\n",
      "Epoch 9, iter 810, loss: 1.0720816850662231\n",
      "Epoch 9, iter 820, loss: 7.269076347351074\n",
      "Epoch 10, iter 0, loss: 1.5469377040863037\n",
      "Epoch 10, iter 10, loss: 2.7804856300354004\n",
      "Epoch 10, iter 20, loss: 2.6830761432647705\n",
      "Epoch 10, iter 30, loss: 3.307467222213745\n",
      "Epoch 10, iter 40, loss: 2.6257777214050293\n",
      "Epoch 10, iter 50, loss: 2.621354341506958\n",
      "Epoch 10, iter 60, loss: 1.3945549726486206\n",
      "Epoch 10, iter 70, loss: 2.1870992183685303\n",
      "Epoch 10, iter 80, loss: 1.9423221349716187\n",
      "Epoch 10, iter 90, loss: 2.014089584350586\n",
      "Epoch 10, iter 100, loss: 1.5645309686660767\n",
      "Epoch 10, iter 110, loss: 1.2036361694335938\n",
      "Epoch 10, iter 120, loss: 1.0012009143829346\n",
      "Epoch 10, iter 130, loss: 8.569753646850586\n",
      "Epoch 10, iter 140, loss: 3.4033687114715576\n",
      "Epoch 10, iter 150, loss: 0.9744410514831543\n",
      "Epoch 10, iter 160, loss: 0.8796327710151672\n",
      "Epoch 10, iter 170, loss: 4.384099006652832\n",
      "Epoch 10, iter 180, loss: 12.475605964660645\n",
      "Epoch 10, iter 190, loss: 2.1700987815856934\n",
      "Epoch 10, iter 200, loss: 1.9448670148849487\n",
      "Epoch 10, iter 210, loss: 7.719905376434326\n",
      "Epoch 10, iter 220, loss: 3.0032331943511963\n",
      "Epoch 10, iter 230, loss: 1.7685402631759644\n",
      "Epoch 10, iter 240, loss: 2.933544158935547\n",
      "Epoch 10, iter 250, loss: 3.613837957382202\n",
      "Epoch 10, iter 260, loss: 8.317181587219238\n",
      "Epoch 10, iter 270, loss: 3.3654935359954834\n",
      "Epoch 10, iter 280, loss: 4.290101051330566\n",
      "Epoch 10, iter 290, loss: 2.340906858444214\n",
      "Epoch 10, iter 300, loss: 2.276994228363037\n",
      "Epoch 10, iter 310, loss: 3.251121997833252\n",
      "Epoch 10, iter 320, loss: 6.65794038772583\n",
      "Epoch 10, iter 330, loss: 1.514796257019043\n",
      "Epoch 10, iter 340, loss: 5.890749454498291\n",
      "Epoch 10, iter 350, loss: 3.018090009689331\n",
      "Epoch 10, iter 360, loss: 5.05126428604126\n",
      "Epoch 10, iter 370, loss: 1.6870912313461304\n",
      "Epoch 10, iter 380, loss: 3.0605297088623047\n",
      "Epoch 10, iter 390, loss: 3.596754550933838\n",
      "Epoch 10, iter 400, loss: 4.694329261779785\n",
      "Epoch 10, iter 410, loss: 5.2097344398498535\n",
      "Epoch 10, iter 420, loss: 2.280834913253784\n",
      "Epoch 10, iter 430, loss: 1.9382716417312622\n",
      "Epoch 10, iter 440, loss: 24.07839584350586\n",
      "Epoch 10, iter 450, loss: 7.31443452835083\n",
      "Epoch 10, iter 460, loss: 5.350950717926025\n",
      "Epoch 10, iter 470, loss: 2.164801836013794\n",
      "Epoch 10, iter 480, loss: 1.325713038444519\n",
      "Epoch 10, iter 490, loss: 1.0638481378555298\n",
      "Epoch 10, iter 500, loss: 1.6047080755233765\n",
      "Epoch 10, iter 510, loss: 5.94492244720459\n",
      "Epoch 10, iter 520, loss: 5.490234375\n",
      "Epoch 10, iter 530, loss: 4.275956153869629\n",
      "Epoch 10, iter 540, loss: 2.1981019973754883\n",
      "Epoch 10, iter 550, loss: 1.5240623950958252\n",
      "Epoch 10, iter 560, loss: 1.5147526264190674\n",
      "Epoch 10, iter 570, loss: 1.1405246257781982\n",
      "Epoch 10, iter 580, loss: 1.6271218061447144\n",
      "Epoch 10, iter 590, loss: 2.5891494750976562\n",
      "Epoch 10, iter 600, loss: 5.835989952087402\n",
      "Epoch 10, iter 610, loss: 31.704999923706055\n",
      "Epoch 10, iter 620, loss: 1.7808867692947388\n",
      "Epoch 10, iter 630, loss: 1.8216646909713745\n",
      "Epoch 10, iter 640, loss: 133.11297607421875\n",
      "Epoch 10, iter 650, loss: 3.950035810470581\n",
      "Epoch 10, iter 660, loss: 1.2853784561157227\n",
      "Epoch 10, iter 670, loss: 4.84025239944458\n",
      "Epoch 10, iter 680, loss: 5.574098110198975\n",
      "Epoch 10, iter 690, loss: 0.9535364508628845\n",
      "Epoch 10, iter 700, loss: 7.844427585601807\n",
      "Epoch 10, iter 710, loss: 0.954054057598114\n",
      "Epoch 10, iter 720, loss: 13.210526466369629\n",
      "Epoch 10, iter 730, loss: 3.244459629058838\n",
      "Epoch 10, iter 740, loss: 0.9059463739395142\n",
      "Epoch 10, iter 750, loss: 4.548774242401123\n",
      "Epoch 10, iter 760, loss: 4.2314372062683105\n",
      "Epoch 10, iter 770, loss: 32.81401443481445\n",
      "Epoch 10, iter 780, loss: 96.77130126953125\n",
      "Epoch 10, iter 790, loss: 1.2501885890960693\n",
      "Epoch 10, iter 800, loss: 0.9976435899734497\n",
      "Epoch 10, iter 810, loss: 0.9334534406661987\n",
      "Epoch 10, iter 820, loss: 2.2639667987823486\n",
      "Epoch 11, iter 0, loss: 5.093019962310791\n",
      "Epoch 11, iter 10, loss: 2.6401455402374268\n",
      "Epoch 11, iter 20, loss: 2.432689905166626\n",
      "Epoch 11, iter 30, loss: 3.4564950466156006\n",
      "Epoch 11, iter 40, loss: 1.8850346803665161\n",
      "Epoch 11, iter 50, loss: 5.3202595710754395\n",
      "Epoch 11, iter 60, loss: 1.8153674602508545\n",
      "Epoch 11, iter 70, loss: 4.623097896575928\n",
      "Epoch 11, iter 80, loss: 1.9334455728530884\n",
      "Epoch 11, iter 90, loss: 5.76155424118042\n",
      "Epoch 11, iter 100, loss: 8.207557678222656\n",
      "Epoch 11, iter 110, loss: 1.9232038259506226\n",
      "Epoch 11, iter 120, loss: 2.652590036392212\n",
      "Epoch 11, iter 130, loss: 2.851123571395874\n",
      "Epoch 11, iter 140, loss: 8.532882690429688\n",
      "Epoch 11, iter 150, loss: 2.622467517852783\n",
      "Epoch 11, iter 160, loss: 15.473661422729492\n",
      "Epoch 11, iter 170, loss: 2.0241005420684814\n",
      "Epoch 11, iter 180, loss: 4.456288814544678\n",
      "Epoch 11, iter 190, loss: 1.0205562114715576\n",
      "Epoch 11, iter 200, loss: 0.9735130667686462\n",
      "Epoch 11, iter 210, loss: 4.9057488441467285\n",
      "Epoch 11, iter 220, loss: 2.694422483444214\n",
      "Epoch 11, iter 230, loss: 2.389914035797119\n",
      "Epoch 11, iter 240, loss: 2.5948588848114014\n",
      "Epoch 11, iter 250, loss: 1.0567790269851685\n",
      "Epoch 11, iter 260, loss: 0.9228686690330505\n",
      "Epoch 11, iter 270, loss: 0.6374081373214722\n",
      "Epoch 11, iter 280, loss: 13.59642505645752\n",
      "Epoch 11, iter 290, loss: 3.8560197353363037\n",
      "Epoch 11, iter 300, loss: 1.2255287170410156\n",
      "Epoch 11, iter 310, loss: 3.8850693702697754\n",
      "Epoch 11, iter 320, loss: 7.729920864105225\n",
      "Epoch 11, iter 330, loss: 1.8199121952056885\n",
      "Epoch 11, iter 340, loss: 3.544668674468994\n",
      "Epoch 11, iter 350, loss: 1.8578205108642578\n",
      "Epoch 11, iter 360, loss: 1.5049599409103394\n",
      "Epoch 11, iter 370, loss: 1.937854528427124\n",
      "Epoch 11, iter 380, loss: 5.347336769104004\n",
      "Epoch 11, iter 390, loss: 1.5882198810577393\n",
      "Epoch 11, iter 400, loss: 2.8261923789978027\n",
      "Epoch 11, iter 410, loss: 1.742315649986267\n",
      "Epoch 11, iter 420, loss: 6.028679847717285\n",
      "Epoch 11, iter 430, loss: 2.9487996101379395\n",
      "Epoch 11, iter 440, loss: 2.613121271133423\n",
      "Epoch 11, iter 450, loss: 1.1864612102508545\n",
      "Epoch 11, iter 460, loss: 2.1886534690856934\n",
      "Epoch 11, iter 470, loss: 1.5293000936508179\n",
      "Epoch 11, iter 480, loss: 9.130572319030762\n",
      "Epoch 11, iter 490, loss: 2.454333782196045\n",
      "Epoch 11, iter 500, loss: 2.9256937503814697\n",
      "Epoch 11, iter 510, loss: 0.7139414548873901\n",
      "Epoch 11, iter 520, loss: 2.3020706176757812\n",
      "Epoch 11, iter 530, loss: 4.1494340896606445\n",
      "Epoch 11, iter 540, loss: 0.5893413424491882\n",
      "Epoch 11, iter 550, loss: 7.868885040283203\n",
      "Epoch 11, iter 560, loss: 6.959609031677246\n",
      "Epoch 11, iter 570, loss: 2.123643636703491\n",
      "Epoch 11, iter 580, loss: 1.6921545267105103\n",
      "Epoch 11, iter 590, loss: 1.8077223300933838\n",
      "Epoch 11, iter 600, loss: 2.159281015396118\n",
      "Epoch 11, iter 610, loss: 3.0753631591796875\n",
      "Epoch 11, iter 620, loss: 1.2949120998382568\n",
      "Epoch 11, iter 630, loss: 0.9876962304115295\n",
      "Epoch 11, iter 640, loss: 1.5012198686599731\n",
      "Epoch 11, iter 650, loss: 9.387158393859863\n",
      "Epoch 11, iter 660, loss: 1.647767186164856\n",
      "Epoch 11, iter 670, loss: 1.5228750705718994\n",
      "Epoch 11, iter 680, loss: 1.212950348854065\n",
      "Epoch 11, iter 690, loss: 2.0140304565429688\n",
      "Epoch 11, iter 700, loss: 3.158985137939453\n",
      "Epoch 11, iter 710, loss: 1.9296882152557373\n",
      "Epoch 11, iter 720, loss: 2.4823977947235107\n",
      "Epoch 11, iter 730, loss: 1.5325391292572021\n",
      "Epoch 11, iter 740, loss: 3.05488920211792\n",
      "Epoch 11, iter 750, loss: 1.1290491819381714\n",
      "Epoch 11, iter 760, loss: 2.3284852504730225\n",
      "Epoch 11, iter 770, loss: 2.558368682861328\n",
      "Epoch 11, iter 780, loss: 3.070275068283081\n",
      "Epoch 11, iter 790, loss: 2.3723416328430176\n",
      "Epoch 11, iter 800, loss: 2.2271602153778076\n",
      "Epoch 11, iter 810, loss: 1.1036454439163208\n",
      "Epoch 11, iter 820, loss: 5.592765808105469\n",
      "Epoch 12, iter 0, loss: 1.8944838047027588\n",
      "Epoch 12, iter 10, loss: 1.0694576501846313\n",
      "Epoch 12, iter 20, loss: 1.8157222270965576\n",
      "Epoch 12, iter 30, loss: 1.4741590023040771\n",
      "Epoch 12, iter 40, loss: 2.0318920612335205\n",
      "Epoch 12, iter 50, loss: 4.388723850250244\n",
      "Epoch 12, iter 60, loss: 3.5065176486968994\n",
      "Epoch 12, iter 70, loss: 0.9866036772727966\n",
      "Epoch 12, iter 80, loss: 3.009089231491089\n",
      "Epoch 12, iter 90, loss: 3.129690647125244\n",
      "Epoch 12, iter 100, loss: 2.2269153594970703\n",
      "Epoch 12, iter 110, loss: 0.5725621581077576\n",
      "Epoch 12, iter 120, loss: 4.721951007843018\n",
      "Epoch 12, iter 130, loss: 3.0078868865966797\n",
      "Epoch 12, iter 140, loss: 2.5607244968414307\n",
      "Epoch 12, iter 150, loss: 2.557128667831421\n",
      "Epoch 12, iter 160, loss: 3.3240811824798584\n",
      "Epoch 12, iter 170, loss: 3.2263035774230957\n",
      "Epoch 12, iter 180, loss: 8.456721305847168\n",
      "Epoch 12, iter 190, loss: 5.457198619842529\n",
      "Epoch 12, iter 200, loss: 3.5425829887390137\n",
      "Epoch 12, iter 210, loss: 2.587888240814209\n",
      "Epoch 12, iter 220, loss: 1.3789364099502563\n",
      "Epoch 12, iter 230, loss: 1.2019561529159546\n",
      "Epoch 12, iter 240, loss: 0.9221758246421814\n",
      "Epoch 12, iter 250, loss: 2.5545036792755127\n",
      "Epoch 12, iter 260, loss: 9.932360649108887\n",
      "Epoch 12, iter 270, loss: 1.2493003606796265\n",
      "Epoch 12, iter 280, loss: 1.6194645166397095\n",
      "Epoch 12, iter 290, loss: 1.2495876550674438\n",
      "Epoch 12, iter 300, loss: 2.216799259185791\n",
      "Epoch 12, iter 310, loss: 0.5278547406196594\n",
      "Epoch 12, iter 320, loss: 1.125172734260559\n",
      "Epoch 12, iter 330, loss: 0.7873215079307556\n",
      "Epoch 12, iter 340, loss: 3.9229750633239746\n",
      "Epoch 12, iter 350, loss: 0.7380067706108093\n",
      "Epoch 12, iter 360, loss: 2.147747755050659\n",
      "Epoch 12, iter 370, loss: 2.2589633464813232\n",
      "Epoch 12, iter 380, loss: 1.0689409971237183\n",
      "Epoch 12, iter 390, loss: 1.2180880308151245\n",
      "Epoch 12, iter 400, loss: 1.1403753757476807\n",
      "Epoch 12, iter 410, loss: 0.765193521976471\n",
      "Epoch 12, iter 420, loss: 1.0357565879821777\n",
      "Epoch 12, iter 430, loss: 2.1477444171905518\n",
      "Epoch 12, iter 440, loss: 1.8496204614639282\n",
      "Epoch 12, iter 450, loss: 1.5317108631134033\n",
      "Epoch 12, iter 460, loss: 1.6079912185668945\n",
      "Epoch 12, iter 470, loss: 1.5408998727798462\n",
      "Epoch 12, iter 480, loss: 4.205461025238037\n",
      "Epoch 12, iter 490, loss: 2.7617669105529785\n",
      "Epoch 12, iter 500, loss: 5.617167949676514\n",
      "Epoch 12, iter 510, loss: 3.7941277027130127\n",
      "Epoch 12, iter 520, loss: 0.825349748134613\n",
      "Epoch 12, iter 530, loss: 2.758681535720825\n",
      "Epoch 12, iter 540, loss: 0.8869085907936096\n",
      "Epoch 12, iter 550, loss: 1.1721456050872803\n",
      "Epoch 12, iter 560, loss: 8.505648612976074\n",
      "Epoch 12, iter 570, loss: 1.7820922136306763\n",
      "Epoch 12, iter 580, loss: 1.7765982151031494\n",
      "Epoch 12, iter 590, loss: 0.5707926154136658\n",
      "Epoch 12, iter 600, loss: 1.664925217628479\n",
      "Epoch 12, iter 610, loss: 94.39110565185547\n",
      "Epoch 12, iter 620, loss: 0.7650361061096191\n",
      "Epoch 12, iter 630, loss: 2.6197640895843506\n",
      "Epoch 12, iter 640, loss: 3.5423455238342285\n",
      "Epoch 12, iter 650, loss: 2.3591177463531494\n",
      "Epoch 12, iter 660, loss: 1.7018896341323853\n",
      "Epoch 12, iter 670, loss: 4.052717685699463\n",
      "Epoch 12, iter 680, loss: 0.7021394371986389\n",
      "Epoch 12, iter 690, loss: 1.4087859392166138\n",
      "Epoch 12, iter 700, loss: 15.0588960647583\n",
      "Epoch 12, iter 710, loss: 0.44714221358299255\n",
      "Epoch 12, iter 720, loss: 15.832427024841309\n",
      "Epoch 12, iter 730, loss: 0.7383822202682495\n",
      "Epoch 12, iter 740, loss: 0.7796978950500488\n",
      "Epoch 12, iter 750, loss: 1.2441776990890503\n",
      "Epoch 12, iter 760, loss: 1.7756201028823853\n",
      "Epoch 12, iter 770, loss: 4.344496250152588\n",
      "Epoch 12, iter 780, loss: 8.388642311096191\n",
      "Epoch 12, iter 790, loss: 3.7655084133148193\n",
      "Epoch 12, iter 800, loss: 2.865036725997925\n",
      "Epoch 12, iter 810, loss: 4.854968547821045\n",
      "Epoch 12, iter 820, loss: 1.31350576877594\n",
      "Epoch 13, iter 0, loss: 4.380588054656982\n",
      "Epoch 13, iter 10, loss: 2.4722018241882324\n",
      "Epoch 13, iter 20, loss: 1.5479724407196045\n",
      "Epoch 13, iter 30, loss: 1.9611314535140991\n",
      "Epoch 13, iter 40, loss: 1.2584275007247925\n",
      "Epoch 13, iter 50, loss: 13.551356315612793\n",
      "Epoch 13, iter 60, loss: 2.3313519954681396\n",
      "Epoch 13, iter 70, loss: 15.851051330566406\n",
      "Epoch 13, iter 80, loss: 4.867859840393066\n",
      "Epoch 13, iter 90, loss: 5.749423027038574\n",
      "Epoch 13, iter 100, loss: 4.22820520401001\n",
      "Epoch 13, iter 110, loss: 13.302286148071289\n",
      "Epoch 13, iter 120, loss: 5.797765254974365\n",
      "Epoch 13, iter 130, loss: 3.0119667053222656\n",
      "Epoch 13, iter 140, loss: 2.2355892658233643\n",
      "Epoch 13, iter 150, loss: 1.214887261390686\n",
      "Epoch 13, iter 160, loss: 1.3707255125045776\n",
      "Epoch 13, iter 170, loss: 2.0506904125213623\n",
      "Epoch 13, iter 180, loss: 8.897531509399414\n",
      "Epoch 13, iter 190, loss: 3.138568639755249\n",
      "Epoch 13, iter 200, loss: 1.8220208883285522\n",
      "Epoch 13, iter 210, loss: 19.3336181640625\n",
      "Epoch 13, iter 220, loss: 2.3666913509368896\n",
      "Epoch 13, iter 230, loss: 2.540935516357422\n",
      "Epoch 13, iter 240, loss: 1.0175999402999878\n",
      "Epoch 13, iter 250, loss: 5.935179710388184\n",
      "Epoch 13, iter 260, loss: 1.4832903146743774\n",
      "Epoch 13, iter 270, loss: 1.292127013206482\n",
      "Epoch 13, iter 280, loss: 11.595663070678711\n",
      "Epoch 13, iter 290, loss: 0.831093430519104\n",
      "Epoch 13, iter 300, loss: 2.5518856048583984\n",
      "Epoch 13, iter 310, loss: 2.091003894805908\n",
      "Epoch 13, iter 320, loss: 3.1177735328674316\n",
      "Epoch 13, iter 330, loss: 0.6507328152656555\n",
      "Epoch 13, iter 340, loss: 2.2140116691589355\n",
      "Epoch 13, iter 350, loss: 4.167086601257324\n",
      "Epoch 13, iter 360, loss: 2.2216007709503174\n",
      "Epoch 13, iter 370, loss: 0.7790559530258179\n",
      "Epoch 13, iter 380, loss: 1.4582622051239014\n",
      "Epoch 13, iter 390, loss: 2.024778366088867\n",
      "Epoch 13, iter 400, loss: 1.4290717840194702\n",
      "Epoch 13, iter 410, loss: 0.6272086501121521\n",
      "Epoch 13, iter 420, loss: 4.960907459259033\n",
      "Epoch 13, iter 430, loss: 0.7540643811225891\n",
      "Epoch 13, iter 440, loss: 0.9940594434738159\n",
      "Epoch 13, iter 450, loss: 1.0550694465637207\n",
      "Epoch 13, iter 460, loss: 1.1870005130767822\n",
      "Epoch 13, iter 470, loss: 0.851249098777771\n",
      "Epoch 13, iter 480, loss: 4.273257255554199\n",
      "Epoch 13, iter 490, loss: 3.4162914752960205\n",
      "Epoch 13, iter 500, loss: 3.5967488288879395\n",
      "Epoch 13, iter 510, loss: 4.266294002532959\n",
      "Epoch 13, iter 520, loss: 0.870210587978363\n",
      "Epoch 13, iter 530, loss: 6.988386631011963\n",
      "Epoch 13, iter 540, loss: 4.875964641571045\n",
      "Epoch 13, iter 550, loss: 4.6972174644470215\n",
      "Epoch 13, iter 560, loss: 6.597997188568115\n",
      "Epoch 13, iter 570, loss: 5.061025142669678\n",
      "Epoch 13, iter 580, loss: 20.77219009399414\n",
      "Epoch 13, iter 590, loss: 3.4104058742523193\n",
      "Epoch 13, iter 600, loss: 2.3204596042633057\n",
      "Epoch 13, iter 610, loss: 2.4563052654266357\n",
      "Epoch 13, iter 620, loss: 3.085702657699585\n",
      "Epoch 13, iter 630, loss: 3.986889362335205\n",
      "Epoch 13, iter 640, loss: 3.8887925148010254\n",
      "Epoch 13, iter 650, loss: 10.136529922485352\n",
      "Epoch 13, iter 660, loss: 1.6145120859146118\n",
      "Epoch 13, iter 670, loss: 5.81569766998291\n",
      "Epoch 13, iter 680, loss: 2.17516827583313\n",
      "Epoch 13, iter 690, loss: 3.8954434394836426\n",
      "Epoch 13, iter 700, loss: 4.28891658782959\n",
      "Epoch 13, iter 710, loss: 2.1576716899871826\n",
      "Epoch 13, iter 720, loss: 3.239194631576538\n",
      "Epoch 13, iter 730, loss: 17.68521499633789\n",
      "Epoch 13, iter 740, loss: 3.3705408573150635\n",
      "Epoch 13, iter 750, loss: 8.198058128356934\n",
      "Epoch 13, iter 760, loss: 2.6201322078704834\n",
      "Epoch 13, iter 770, loss: 0.7600897550582886\n",
      "Epoch 13, iter 780, loss: 0.4259102940559387\n",
      "Epoch 13, iter 790, loss: 3.099677801132202\n",
      "Epoch 13, iter 800, loss: 3.0618128776550293\n",
      "Epoch 13, iter 810, loss: 1.1008461713790894\n",
      "Epoch 13, iter 820, loss: 1.5479248762130737\n",
      "Epoch 14, iter 0, loss: 1.616514801979065\n",
      "Epoch 14, iter 10, loss: 1.109284520149231\n",
      "Epoch 14, iter 20, loss: 3.8864481449127197\n",
      "Epoch 14, iter 30, loss: 51.32517623901367\n",
      "Epoch 14, iter 40, loss: 2.6307199001312256\n",
      "Epoch 14, iter 50, loss: 1.3667447566986084\n",
      "Epoch 14, iter 60, loss: 3.1260087490081787\n",
      "Epoch 14, iter 70, loss: 8.475153923034668\n",
      "Epoch 14, iter 80, loss: 5.574924468994141\n",
      "Epoch 14, iter 90, loss: 2.208202362060547\n",
      "Epoch 14, iter 100, loss: 3.1969521045684814\n",
      "Epoch 14, iter 110, loss: 1.7462676763534546\n",
      "Epoch 14, iter 120, loss: 3.101205587387085\n",
      "Epoch 14, iter 130, loss: 4.0232086181640625\n",
      "Epoch 14, iter 140, loss: 3.1570587158203125\n",
      "Epoch 14, iter 150, loss: 2.7871882915496826\n",
      "Epoch 14, iter 160, loss: 1.5050365924835205\n",
      "Epoch 14, iter 170, loss: 1.8801062107086182\n",
      "Epoch 14, iter 180, loss: 2.7930655479431152\n",
      "Epoch 14, iter 190, loss: 1.2600606679916382\n",
      "Epoch 14, iter 200, loss: 1.8776408433914185\n",
      "Epoch 14, iter 210, loss: 8.77188777923584\n",
      "Epoch 14, iter 220, loss: 2.3944766521453857\n",
      "Epoch 14, iter 230, loss: 18.397920608520508\n",
      "Epoch 14, iter 240, loss: 1.344268560409546\n",
      "Epoch 14, iter 250, loss: 3.251178741455078\n",
      "Epoch 14, iter 260, loss: 1.108476161956787\n",
      "Epoch 14, iter 270, loss: 1.9633301496505737\n",
      "Epoch 14, iter 280, loss: 0.5709782242774963\n",
      "Epoch 14, iter 290, loss: 2.675790548324585\n",
      "Epoch 14, iter 300, loss: 2.347590208053589\n",
      "Epoch 14, iter 310, loss: 5.086499214172363\n",
      "Epoch 14, iter 320, loss: 0.4714406430721283\n",
      "Epoch 14, iter 330, loss: 2.6574530601501465\n",
      "Epoch 14, iter 340, loss: 4.971161842346191\n",
      "Epoch 14, iter 350, loss: 4.6923322677612305\n",
      "Epoch 14, iter 360, loss: 0.41733646392822266\n",
      "Epoch 14, iter 370, loss: 24.77976417541504\n",
      "Epoch 14, iter 380, loss: 1.115160584449768\n",
      "Epoch 14, iter 390, loss: 0.648504912853241\n",
      "Epoch 14, iter 400, loss: 1.376753807067871\n",
      "Epoch 14, iter 410, loss: 1.6589620113372803\n",
      "Epoch 14, iter 420, loss: 1.075016736984253\n",
      "Epoch 14, iter 430, loss: 0.8910884857177734\n",
      "Epoch 14, iter 440, loss: 0.9978537559509277\n",
      "Epoch 14, iter 450, loss: 1.3351398706436157\n",
      "Epoch 14, iter 460, loss: 2.854081869125366\n",
      "Epoch 14, iter 470, loss: 1.5911146402359009\n",
      "Epoch 14, iter 480, loss: 2.418748617172241\n",
      "Epoch 14, iter 490, loss: 3.6359946727752686\n",
      "Epoch 14, iter 500, loss: 1.28542160987854\n",
      "Epoch 14, iter 510, loss: 0.8865718841552734\n",
      "Epoch 14, iter 520, loss: 0.38193830847740173\n",
      "Epoch 14, iter 530, loss: 0.7457260489463806\n",
      "Epoch 14, iter 540, loss: 6.771798133850098\n",
      "Epoch 14, iter 550, loss: 1.0016882419586182\n",
      "Epoch 14, iter 560, loss: 1.6322734355926514\n",
      "Epoch 14, iter 570, loss: 0.7713078260421753\n",
      "Epoch 14, iter 580, loss: 0.6956766843795776\n",
      "Epoch 14, iter 590, loss: 9.525559425354004\n",
      "Epoch 14, iter 600, loss: 0.7426000237464905\n",
      "Epoch 14, iter 610, loss: 2.399197816848755\n",
      "Epoch 14, iter 620, loss: 3.4433434009552\n",
      "Epoch 14, iter 630, loss: 1.2669165134429932\n",
      "Epoch 14, iter 640, loss: 1.4621264934539795\n",
      "Epoch 14, iter 650, loss: 2.0460739135742188\n",
      "Epoch 14, iter 660, loss: 0.7576681971549988\n",
      "Epoch 14, iter 670, loss: 2.4936869144439697\n",
      "Epoch 14, iter 680, loss: 2.64715838432312\n",
      "Epoch 14, iter 690, loss: 1.9144176244735718\n",
      "Epoch 14, iter 700, loss: 2.9305341243743896\n",
      "Epoch 14, iter 710, loss: 3.1344738006591797\n",
      "Epoch 14, iter 720, loss: 0.529212236404419\n",
      "Epoch 14, iter 730, loss: 0.5829104781150818\n",
      "Epoch 14, iter 740, loss: 2.0376744270324707\n",
      "Epoch 14, iter 750, loss: 3.5381762981414795\n",
      "Epoch 14, iter 760, loss: 1.8825956583023071\n",
      "Epoch 14, iter 770, loss: 1.83111572265625\n",
      "Epoch 14, iter 780, loss: 1.356078863143921\n",
      "Epoch 14, iter 790, loss: 2.07481050491333\n",
      "Epoch 14, iter 800, loss: 1.4602309465408325\n",
      "Epoch 14, iter 810, loss: 0.5969443917274475\n",
      "Epoch 14, iter 820, loss: 0.3703344762325287\n",
      "Epoch 15, iter 0, loss: 0.7429505586624146\n",
      "Epoch 15, iter 10, loss: 0.7380322813987732\n",
      "Epoch 15, iter 20, loss: 1.4374077320098877\n",
      "Epoch 15, iter 30, loss: 0.6194185018539429\n",
      "Epoch 15, iter 40, loss: 2.635288953781128\n",
      "Epoch 15, iter 50, loss: 1.596986174583435\n",
      "Epoch 15, iter 60, loss: 0.5941537618637085\n",
      "Epoch 15, iter 70, loss: 1.1908198595046997\n",
      "Epoch 15, iter 80, loss: 1.0656288862228394\n",
      "Epoch 15, iter 90, loss: 0.9769924283027649\n",
      "Epoch 15, iter 100, loss: 0.7632981538772583\n",
      "Epoch 15, iter 110, loss: 1.267190933227539\n",
      "Epoch 15, iter 120, loss: 0.8868141174316406\n",
      "Epoch 15, iter 130, loss: 1.6791315078735352\n",
      "Epoch 15, iter 140, loss: 0.46672454476356506\n",
      "Epoch 15, iter 150, loss: 2.841679096221924\n",
      "Epoch 15, iter 160, loss: 2.205089807510376\n",
      "Epoch 15, iter 170, loss: 9.126744270324707\n",
      "Epoch 15, iter 180, loss: 1.4367268085479736\n",
      "Epoch 15, iter 190, loss: 0.6295507550239563\n",
      "Epoch 15, iter 200, loss: 0.7201434373855591\n",
      "Epoch 15, iter 210, loss: 4.002727508544922\n",
      "Epoch 15, iter 220, loss: 0.6133604645729065\n",
      "Epoch 15, iter 230, loss: 0.9207572937011719\n",
      "Epoch 15, iter 240, loss: 0.4367227256298065\n",
      "Epoch 15, iter 250, loss: 8.435189247131348\n",
      "Epoch 15, iter 260, loss: 1.0019255876541138\n",
      "Epoch 15, iter 270, loss: 3.6113085746765137\n",
      "Epoch 15, iter 280, loss: 123.10975646972656\n",
      "Epoch 15, iter 290, loss: 1.4906874895095825\n",
      "Epoch 15, iter 300, loss: 1.280462384223938\n",
      "Epoch 15, iter 310, loss: 1.2587960958480835\n",
      "Epoch 15, iter 320, loss: 3.464221954345703\n",
      "Epoch 15, iter 330, loss: 4.635307788848877\n",
      "Epoch 15, iter 340, loss: 0.8867226243019104\n",
      "Epoch 15, iter 350, loss: 1.8946301937103271\n",
      "Epoch 15, iter 360, loss: 1.7185391187667847\n",
      "Epoch 15, iter 370, loss: 2.3265492916107178\n",
      "Epoch 15, iter 380, loss: 4.777743816375732\n",
      "Epoch 15, iter 390, loss: 1.7957667112350464\n",
      "Epoch 15, iter 400, loss: 1.0494633913040161\n",
      "Epoch 15, iter 410, loss: 1.417144775390625\n",
      "Epoch 15, iter 420, loss: 4.941794395446777\n",
      "Epoch 15, iter 430, loss: 2.6447012424468994\n",
      "Epoch 15, iter 440, loss: 0.9954553246498108\n",
      "Epoch 15, iter 450, loss: 4.093423366546631\n",
      "Epoch 15, iter 460, loss: 2.809508800506592\n",
      "Epoch 15, iter 470, loss: 1.2407485246658325\n",
      "Epoch 15, iter 480, loss: 1.5725106000900269\n",
      "Epoch 15, iter 490, loss: 2.987305164337158\n",
      "Epoch 15, iter 500, loss: 1.0271327495574951\n",
      "Epoch 15, iter 510, loss: 2.478233575820923\n",
      "Epoch 15, iter 520, loss: 0.5766869783401489\n",
      "Epoch 15, iter 530, loss: 1.347525715827942\n",
      "Epoch 15, iter 540, loss: 1.0512796640396118\n",
      "Epoch 15, iter 550, loss: 2.37691330909729\n",
      "Epoch 15, iter 560, loss: 4.122079372406006\n",
      "Epoch 15, iter 570, loss: 2.409832239151001\n",
      "Epoch 15, iter 580, loss: 15.024434089660645\n",
      "Epoch 15, iter 590, loss: 2.9843404293060303\n",
      "Epoch 15, iter 600, loss: 6.4560956954956055\n",
      "Epoch 15, iter 610, loss: 2.1867995262145996\n",
      "Epoch 15, iter 620, loss: 6.241887092590332\n",
      "Epoch 15, iter 630, loss: 1.2496033906936646\n",
      "Epoch 15, iter 640, loss: 2.5523343086242676\n",
      "Epoch 15, iter 650, loss: 2.1424388885498047\n",
      "Epoch 15, iter 660, loss: 17.48695945739746\n",
      "Epoch 15, iter 670, loss: 2.9426658153533936\n",
      "Epoch 15, iter 680, loss: 1.6834520101547241\n",
      "Epoch 15, iter 690, loss: 0.8241475820541382\n",
      "Epoch 15, iter 700, loss: 0.6258353590965271\n",
      "Epoch 15, iter 710, loss: 0.7632321715354919\n",
      "Epoch 15, iter 720, loss: 3.187568187713623\n",
      "Epoch 15, iter 730, loss: 1.1558815240859985\n",
      "Epoch 15, iter 740, loss: 5.780876636505127\n",
      "Epoch 15, iter 750, loss: 2.1753933429718018\n",
      "Epoch 15, iter 760, loss: 3.3775806427001953\n",
      "Epoch 15, iter 770, loss: 3.0493509769439697\n",
      "Epoch 15, iter 780, loss: 90.05896759033203\n",
      "Epoch 15, iter 790, loss: 1.6209707260131836\n",
      "Epoch 15, iter 800, loss: 1.2474863529205322\n",
      "Epoch 15, iter 810, loss: 6.033755302429199\n",
      "Epoch 15, iter 820, loss: 0.8243729472160339\n",
      "Epoch 16, iter 0, loss: 0.9720187783241272\n",
      "Epoch 16, iter 10, loss: 1.4313100576400757\n",
      "Epoch 16, iter 20, loss: 1.4370543956756592\n",
      "Epoch 16, iter 30, loss: 0.6916657090187073\n",
      "Epoch 16, iter 40, loss: 0.8730860948562622\n",
      "Epoch 16, iter 50, loss: 2.1982715129852295\n",
      "Epoch 16, iter 60, loss: 2.4556148052215576\n",
      "Epoch 16, iter 70, loss: 1.0622670650482178\n",
      "Epoch 16, iter 80, loss: 1.3070498704910278\n",
      "Epoch 16, iter 90, loss: 3.2532589435577393\n",
      "Epoch 16, iter 100, loss: 0.3195115923881531\n",
      "Epoch 16, iter 110, loss: 1.1608669757843018\n",
      "Epoch 16, iter 120, loss: 2.245398998260498\n",
      "Epoch 16, iter 130, loss: 1.2126051187515259\n",
      "Epoch 16, iter 140, loss: 2.1555190086364746\n",
      "Epoch 16, iter 150, loss: 1.286166787147522\n",
      "Epoch 16, iter 160, loss: 3.3959102630615234\n",
      "Epoch 16, iter 170, loss: 2.031909227371216\n",
      "Epoch 16, iter 180, loss: 2.3755953311920166\n",
      "Epoch 16, iter 190, loss: 0.35892805457115173\n",
      "Epoch 16, iter 200, loss: 1.2098820209503174\n",
      "Epoch 16, iter 210, loss: 1.4821765422821045\n",
      "Epoch 16, iter 220, loss: 2.333070993423462\n",
      "Epoch 16, iter 230, loss: 0.8852076530456543\n",
      "Epoch 16, iter 240, loss: 12.99149227142334\n",
      "Epoch 16, iter 250, loss: 2.2571513652801514\n",
      "Epoch 16, iter 260, loss: 0.805563747882843\n",
      "Epoch 16, iter 270, loss: 2.4710605144500732\n",
      "Epoch 16, iter 280, loss: 1.0741275548934937\n",
      "Epoch 16, iter 290, loss: 0.5576913952827454\n",
      "Epoch 16, iter 300, loss: 84.42337799072266\n",
      "Epoch 16, iter 310, loss: 1.5146042108535767\n",
      "Epoch 16, iter 320, loss: 1.4794915914535522\n",
      "Epoch 16, iter 330, loss: 0.6787136793136597\n",
      "Epoch 16, iter 340, loss: 0.6513907313346863\n",
      "Epoch 16, iter 350, loss: 3.8772599697113037\n",
      "Epoch 16, iter 360, loss: 2.2072513103485107\n",
      "Epoch 16, iter 370, loss: 5.826828479766846\n",
      "Epoch 16, iter 380, loss: 0.6986492276191711\n",
      "Epoch 16, iter 390, loss: 0.9850965142250061\n",
      "Epoch 16, iter 400, loss: 0.8657850027084351\n",
      "Epoch 16, iter 410, loss: 1.8776423931121826\n",
      "Epoch 16, iter 420, loss: 109.27400970458984\n",
      "Epoch 16, iter 430, loss: 2.824028491973877\n",
      "Epoch 16, iter 440, loss: 1.3628801107406616\n",
      "Epoch 16, iter 450, loss: 0.8459979295730591\n",
      "Epoch 16, iter 460, loss: 1.4940861463546753\n",
      "Epoch 16, iter 470, loss: 13.313389778137207\n",
      "Epoch 16, iter 480, loss: 2.107827663421631\n",
      "Epoch 16, iter 490, loss: 1.565869927406311\n",
      "Epoch 16, iter 500, loss: 2.3671319484710693\n",
      "Epoch 16, iter 510, loss: 4.305591106414795\n",
      "Epoch 16, iter 520, loss: 14.057877540588379\n",
      "Epoch 16, iter 530, loss: 1.88783860206604\n",
      "Epoch 16, iter 540, loss: 0.5693050622940063\n",
      "Epoch 16, iter 550, loss: 0.7069196105003357\n",
      "Epoch 16, iter 560, loss: 1.4825079441070557\n",
      "Epoch 16, iter 570, loss: 1.678073525428772\n",
      "Epoch 16, iter 580, loss: 1.8109651803970337\n",
      "Epoch 16, iter 590, loss: 0.47684532403945923\n",
      "Epoch 16, iter 600, loss: 0.9543260931968689\n",
      "Epoch 16, iter 610, loss: 0.8913941383361816\n",
      "Epoch 16, iter 620, loss: 1.66071617603302\n",
      "Epoch 16, iter 630, loss: 0.7728773951530457\n",
      "Epoch 16, iter 640, loss: 0.864165186882019\n",
      "Epoch 16, iter 650, loss: 0.44823482632637024\n",
      "Epoch 16, iter 660, loss: 82.81370544433594\n",
      "Epoch 16, iter 670, loss: 1.7113800048828125\n",
      "Epoch 16, iter 680, loss: 1.0447739362716675\n",
      "Epoch 16, iter 690, loss: 0.8347509503364563\n",
      "Epoch 16, iter 700, loss: 1.680323839187622\n",
      "Epoch 16, iter 710, loss: 0.45188838243484497\n",
      "Epoch 16, iter 720, loss: 2.741091012954712\n",
      "Epoch 16, iter 730, loss: 1.0537663698196411\n",
      "Epoch 16, iter 740, loss: 0.3620666563510895\n",
      "Epoch 16, iter 750, loss: 1.3970028162002563\n",
      "Epoch 16, iter 760, loss: 0.9524683952331543\n",
      "Epoch 16, iter 770, loss: 1.185578465461731\n",
      "Epoch 16, iter 780, loss: 3.304177761077881\n",
      "Epoch 16, iter 790, loss: 0.7146681547164917\n",
      "Epoch 16, iter 800, loss: 1.4577901363372803\n",
      "Epoch 16, iter 810, loss: 0.6426119208335876\n",
      "Epoch 16, iter 820, loss: 0.6907508969306946\n",
      "Epoch 17, iter 0, loss: 3.243934154510498\n",
      "Epoch 17, iter 10, loss: 12.32887077331543\n",
      "Epoch 17, iter 20, loss: 1.8781630992889404\n",
      "Epoch 17, iter 30, loss: 1.9306256771087646\n",
      "Epoch 17, iter 40, loss: 0.7281293272972107\n",
      "Epoch 17, iter 50, loss: 0.7285534739494324\n",
      "Epoch 17, iter 60, loss: 0.4542965292930603\n",
      "Epoch 17, iter 70, loss: 3.075857400894165\n",
      "Epoch 17, iter 80, loss: 2.23174786567688\n",
      "Epoch 17, iter 90, loss: 7.839523792266846\n",
      "Epoch 17, iter 100, loss: 0.8534894585609436\n",
      "Epoch 17, iter 110, loss: 1.2572065591812134\n",
      "Epoch 17, iter 120, loss: 2.5828824043273926\n",
      "Epoch 17, iter 130, loss: 2.1700453758239746\n",
      "Epoch 17, iter 140, loss: 2.256133556365967\n",
      "Epoch 17, iter 150, loss: 2.364194869995117\n",
      "Epoch 17, iter 160, loss: 1.8411977291107178\n",
      "Epoch 17, iter 170, loss: 1.3658937215805054\n",
      "Epoch 17, iter 180, loss: 0.642059326171875\n",
      "Epoch 17, iter 190, loss: 0.7455474734306335\n",
      "Epoch 17, iter 200, loss: 1.7627049684524536\n",
      "Epoch 17, iter 210, loss: 0.8126499056816101\n",
      "Epoch 17, iter 220, loss: 1.3463811874389648\n",
      "Epoch 17, iter 230, loss: 0.3223411738872528\n",
      "Epoch 17, iter 240, loss: 1.3880136013031006\n",
      "Epoch 17, iter 250, loss: 0.9020510911941528\n",
      "Epoch 17, iter 260, loss: 1.5586044788360596\n",
      "Epoch 17, iter 270, loss: 1.0687294006347656\n",
      "Epoch 17, iter 280, loss: 0.9899182915687561\n",
      "Epoch 17, iter 290, loss: 0.7777950167655945\n",
      "Epoch 17, iter 300, loss: 6.999993801116943\n",
      "Epoch 17, iter 310, loss: 1.0780823230743408\n",
      "Epoch 17, iter 320, loss: 0.9147788286209106\n",
      "Epoch 17, iter 330, loss: 0.7855345606803894\n",
      "Epoch 17, iter 340, loss: 0.7943762540817261\n",
      "Epoch 17, iter 350, loss: 1.1012409925460815\n",
      "Epoch 17, iter 360, loss: 1.1798124313354492\n",
      "Epoch 17, iter 370, loss: 2.206511974334717\n",
      "Epoch 17, iter 380, loss: 0.6604992151260376\n",
      "Epoch 17, iter 390, loss: 1.6372140645980835\n",
      "Epoch 17, iter 400, loss: 0.9574576616287231\n",
      "Epoch 17, iter 410, loss: 0.958683431148529\n",
      "Epoch 17, iter 420, loss: 0.3553133010864258\n",
      "Epoch 17, iter 430, loss: 1.1495457887649536\n",
      "Epoch 17, iter 440, loss: 0.6305719614028931\n",
      "Epoch 17, iter 450, loss: 0.616071343421936\n",
      "Epoch 17, iter 460, loss: 0.6483597755432129\n",
      "Epoch 17, iter 470, loss: 0.6220893263816833\n",
      "Epoch 17, iter 480, loss: 0.3738013803958893\n",
      "Epoch 17, iter 490, loss: 1.0883890390396118\n",
      "Epoch 17, iter 500, loss: 4.21684455871582\n",
      "Epoch 17, iter 510, loss: 2.4648349285125732\n",
      "Epoch 17, iter 520, loss: 1.9261821508407593\n",
      "Epoch 17, iter 530, loss: 0.8466777801513672\n",
      "Epoch 17, iter 540, loss: 1.8683290481567383\n",
      "Epoch 17, iter 550, loss: 0.7252444624900818\n",
      "Epoch 17, iter 560, loss: 0.4729977250099182\n",
      "Epoch 17, iter 570, loss: 0.7969823479652405\n",
      "Epoch 17, iter 580, loss: 0.751735508441925\n",
      "Epoch 17, iter 590, loss: 0.6684190630912781\n",
      "Epoch 17, iter 600, loss: 0.4213644564151764\n",
      "Epoch 17, iter 610, loss: 1.1367982625961304\n",
      "Epoch 17, iter 620, loss: 0.5006895661354065\n",
      "Epoch 17, iter 630, loss: 0.6055004000663757\n",
      "Epoch 17, iter 640, loss: 0.6422869563102722\n",
      "Epoch 17, iter 650, loss: 2.937408447265625\n",
      "Epoch 17, iter 660, loss: 1.386435866355896\n",
      "Epoch 17, iter 670, loss: 0.7753347158432007\n",
      "Epoch 17, iter 680, loss: 0.4765266478061676\n",
      "Epoch 17, iter 690, loss: 0.9388346672058105\n",
      "Epoch 17, iter 700, loss: 0.528141438961029\n",
      "Epoch 17, iter 710, loss: 0.5017982721328735\n",
      "Epoch 17, iter 720, loss: 0.8135048151016235\n",
      "Epoch 17, iter 730, loss: 26.494699478149414\n",
      "Epoch 17, iter 740, loss: 4.093979835510254\n",
      "Epoch 17, iter 750, loss: 0.7406054139137268\n",
      "Epoch 17, iter 760, loss: 1.6782256364822388\n",
      "Epoch 17, iter 770, loss: 1.137171983718872\n",
      "Epoch 17, iter 780, loss: 0.7023298144340515\n",
      "Epoch 17, iter 790, loss: 0.8841823935508728\n",
      "Epoch 17, iter 800, loss: 0.7977504730224609\n",
      "Epoch 17, iter 810, loss: 0.6330339312553406\n",
      "Epoch 17, iter 820, loss: 0.8309860229492188\n",
      "Epoch 18, iter 0, loss: 0.45273011922836304\n",
      "Epoch 18, iter 10, loss: 1.3750079870224\n",
      "Epoch 18, iter 20, loss: 2.4891040325164795\n",
      "Epoch 18, iter 30, loss: 0.9170021414756775\n",
      "Epoch 18, iter 40, loss: 0.3188004493713379\n",
      "Epoch 18, iter 50, loss: 1.0012962818145752\n",
      "Epoch 18, iter 60, loss: 0.5550744533538818\n",
      "Epoch 18, iter 70, loss: 0.8833970427513123\n",
      "Epoch 18, iter 80, loss: 0.6676524877548218\n",
      "Epoch 18, iter 90, loss: 1.5264475345611572\n",
      "Epoch 18, iter 100, loss: 70.58924102783203\n",
      "Epoch 18, iter 110, loss: 1.2725131511688232\n",
      "Epoch 18, iter 120, loss: 1.079760193824768\n",
      "Epoch 18, iter 130, loss: 1.0299897193908691\n",
      "Epoch 18, iter 140, loss: 0.45684814453125\n",
      "Epoch 18, iter 150, loss: 1.5182844400405884\n",
      "Epoch 18, iter 160, loss: 0.5629376173019409\n",
      "Epoch 18, iter 170, loss: 15.145133018493652\n",
      "Epoch 18, iter 180, loss: 0.8664493560791016\n",
      "Epoch 18, iter 190, loss: 1.624516248703003\n",
      "Epoch 18, iter 200, loss: 0.9240490198135376\n",
      "Epoch 18, iter 210, loss: 3.3736698627471924\n",
      "Epoch 18, iter 220, loss: 1.4027595520019531\n",
      "Epoch 18, iter 230, loss: 2.0726139545440674\n",
      "Epoch 18, iter 240, loss: 1.1399980783462524\n",
      "Epoch 18, iter 250, loss: 1.6918679475784302\n",
      "Epoch 18, iter 260, loss: 0.9205721616744995\n",
      "Epoch 18, iter 270, loss: 1.0689347982406616\n",
      "Epoch 18, iter 280, loss: 1.164149522781372\n",
      "Epoch 18, iter 290, loss: 0.8418516516685486\n",
      "Epoch 18, iter 300, loss: 0.9889990091323853\n",
      "Epoch 18, iter 310, loss: 0.6617120504379272\n",
      "Epoch 18, iter 320, loss: 8.218165397644043\n",
      "Epoch 18, iter 330, loss: 1.8755781650543213\n",
      "Epoch 18, iter 340, loss: 1.8751686811447144\n",
      "Epoch 18, iter 350, loss: 0.6633811593055725\n",
      "Epoch 18, iter 360, loss: 14.498190879821777\n",
      "Epoch 18, iter 370, loss: 1.9470921754837036\n",
      "Epoch 18, iter 380, loss: 0.2797733545303345\n",
      "Epoch 18, iter 390, loss: 1.9297245740890503\n",
      "Epoch 18, iter 400, loss: 0.6307636499404907\n",
      "Epoch 18, iter 410, loss: 1.295606017112732\n",
      "Epoch 18, iter 420, loss: 1.2655338048934937\n",
      "Epoch 18, iter 430, loss: 0.44451215863227844\n",
      "Epoch 18, iter 440, loss: 0.7906008362770081\n",
      "Epoch 18, iter 450, loss: 0.4929465651512146\n",
      "Epoch 18, iter 460, loss: 2.5567126274108887\n",
      "Epoch 18, iter 470, loss: 1.5064424276351929\n",
      "Epoch 18, iter 480, loss: 2.1935365200042725\n",
      "Epoch 18, iter 490, loss: 1.921656847000122\n",
      "Epoch 18, iter 500, loss: 0.9677683711051941\n",
      "Epoch 18, iter 510, loss: 0.6483072638511658\n",
      "Epoch 18, iter 520, loss: 2.230926990509033\n",
      "Epoch 18, iter 530, loss: 1.1150964498519897\n",
      "Epoch 18, iter 540, loss: 1.0760244131088257\n",
      "Epoch 18, iter 550, loss: 1.0542391538619995\n",
      "Epoch 18, iter 560, loss: 0.8551493883132935\n",
      "Epoch 18, iter 570, loss: 1.0390512943267822\n",
      "Epoch 18, iter 580, loss: 5.862776756286621\n",
      "Epoch 18, iter 590, loss: 0.8571224212646484\n",
      "Epoch 18, iter 600, loss: 0.9547292590141296\n",
      "Epoch 18, iter 610, loss: 0.44507572054862976\n",
      "Epoch 18, iter 620, loss: 1.1238563060760498\n",
      "Epoch 18, iter 630, loss: 3.0963187217712402\n",
      "Epoch 18, iter 640, loss: 1.7272464036941528\n",
      "Epoch 18, iter 650, loss: 0.97911536693573\n",
      "Epoch 18, iter 660, loss: 0.49637460708618164\n",
      "Epoch 18, iter 670, loss: 0.5607991814613342\n",
      "Epoch 18, iter 680, loss: 5.358248710632324\n",
      "Epoch 18, iter 690, loss: 0.6545554995536804\n",
      "Epoch 18, iter 700, loss: 0.3541598916053772\n",
      "Epoch 18, iter 710, loss: 0.9620881676673889\n",
      "Epoch 18, iter 720, loss: 0.30069828033447266\n",
      "Epoch 18, iter 730, loss: 0.9921185374259949\n",
      "Epoch 18, iter 740, loss: 3.204951524734497\n",
      "Epoch 18, iter 750, loss: 2.6867618560791016\n",
      "Epoch 18, iter 760, loss: 1.1987851858139038\n",
      "Epoch 18, iter 770, loss: 0.40228670835494995\n",
      "Epoch 18, iter 780, loss: 0.662158191204071\n",
      "Epoch 18, iter 790, loss: 2.414154291152954\n",
      "Epoch 18, iter 800, loss: 0.7687962651252747\n",
      "Epoch 18, iter 810, loss: 0.39617156982421875\n",
      "Epoch 18, iter 820, loss: 0.4836885631084442\n",
      "Epoch 19, iter 0, loss: 2.4177165031433105\n",
      "Epoch 19, iter 10, loss: 1.709599494934082\n",
      "Epoch 19, iter 20, loss: 2.0076088905334473\n",
      "Epoch 19, iter 30, loss: 1.3354532718658447\n",
      "Epoch 19, iter 40, loss: 0.7855942845344543\n",
      "Epoch 19, iter 50, loss: 0.9685786366462708\n",
      "Epoch 19, iter 60, loss: 0.24641545116901398\n",
      "Epoch 19, iter 70, loss: 0.5286845564842224\n",
      "Epoch 19, iter 80, loss: 2.094973087310791\n",
      "Epoch 19, iter 90, loss: 1.6779338121414185\n",
      "Epoch 19, iter 100, loss: 6.695689678192139\n",
      "Epoch 19, iter 110, loss: 2.385423421859741\n",
      "Epoch 19, iter 120, loss: 0.7943798899650574\n",
      "Epoch 19, iter 130, loss: 1.4996833801269531\n",
      "Epoch 19, iter 140, loss: 1.0861784219741821\n",
      "Epoch 19, iter 150, loss: 11.14332103729248\n",
      "Epoch 19, iter 160, loss: 1.043871283531189\n",
      "Epoch 19, iter 170, loss: 1.8090332746505737\n",
      "Epoch 19, iter 180, loss: 0.9655975699424744\n",
      "Epoch 19, iter 190, loss: 0.6330612897872925\n",
      "Epoch 19, iter 200, loss: 0.5238780379295349\n",
      "Epoch 19, iter 210, loss: 0.6126235127449036\n",
      "Epoch 19, iter 220, loss: 7.42931604385376\n",
      "Epoch 19, iter 230, loss: 2.487169027328491\n",
      "Epoch 19, iter 240, loss: 1.1597996950149536\n",
      "Epoch 19, iter 250, loss: 0.79006427526474\n",
      "Epoch 19, iter 260, loss: 0.9191619157791138\n",
      "Epoch 19, iter 270, loss: 0.8642095923423767\n",
      "Epoch 19, iter 280, loss: 0.9704570174217224\n",
      "Epoch 19, iter 290, loss: 0.5535340309143066\n",
      "Epoch 19, iter 300, loss: 0.46832942962646484\n",
      "Epoch 19, iter 310, loss: 0.8505261540412903\n",
      "Epoch 19, iter 320, loss: 0.6448550224304199\n",
      "Epoch 19, iter 330, loss: 1.4831310510635376\n",
      "Epoch 19, iter 340, loss: 0.7985265851020813\n",
      "Epoch 19, iter 350, loss: 1.5831162929534912\n",
      "Epoch 19, iter 360, loss: 1.524094820022583\n",
      "Epoch 19, iter 370, loss: 0.8936896920204163\n",
      "Epoch 19, iter 380, loss: 1.013105869293213\n",
      "Epoch 19, iter 390, loss: 0.9770415425300598\n",
      "Epoch 19, iter 400, loss: 0.5516669154167175\n",
      "Epoch 19, iter 410, loss: 0.46086767315864563\n",
      "Epoch 19, iter 420, loss: 0.5665074586868286\n",
      "Epoch 19, iter 430, loss: 0.45527082681655884\n",
      "Epoch 19, iter 440, loss: 0.35279616713523865\n",
      "Epoch 19, iter 450, loss: 0.5539476275444031\n",
      "Epoch 19, iter 460, loss: 1.2094534635543823\n",
      "Epoch 19, iter 470, loss: 1.6032114028930664\n",
      "Epoch 19, iter 480, loss: 1.876992106437683\n",
      "Epoch 19, iter 490, loss: 2.3984358310699463\n",
      "Epoch 19, iter 500, loss: 3.706129789352417\n",
      "Epoch 19, iter 510, loss: 0.9744092226028442\n",
      "Epoch 19, iter 520, loss: 2.1964800357818604\n",
      "Epoch 19, iter 530, loss: 1.5334320068359375\n",
      "Epoch 19, iter 540, loss: 1.6564286947250366\n",
      "Epoch 19, iter 550, loss: 2.444392681121826\n",
      "Epoch 19, iter 560, loss: 0.632296085357666\n",
      "Epoch 19, iter 570, loss: 0.9557703733444214\n",
      "Epoch 19, iter 580, loss: 1.1215296983718872\n",
      "Epoch 19, iter 590, loss: 0.7657866477966309\n",
      "Epoch 19, iter 600, loss: 0.8256932497024536\n",
      "Epoch 19, iter 610, loss: 1.916048288345337\n",
      "Epoch 19, iter 620, loss: 3.545588254928589\n",
      "Epoch 19, iter 630, loss: 0.7474967837333679\n",
      "Epoch 19, iter 640, loss: 3.7355473041534424\n",
      "Epoch 19, iter 650, loss: 0.7704530358314514\n",
      "Epoch 19, iter 660, loss: 1.4469070434570312\n",
      "Epoch 19, iter 670, loss: 0.7509501576423645\n",
      "Epoch 19, iter 680, loss: 1.3811464309692383\n",
      "Epoch 19, iter 690, loss: 0.6286633610725403\n",
      "Epoch 19, iter 700, loss: 0.6320083737373352\n",
      "Epoch 19, iter 710, loss: 1.267175316810608\n",
      "Epoch 19, iter 720, loss: 0.6843886971473694\n",
      "Epoch 19, iter 730, loss: 1.7212308645248413\n",
      "Epoch 19, iter 740, loss: 1.0144301652908325\n",
      "Epoch 19, iter 750, loss: 3.4627528190612793\n",
      "Epoch 19, iter 760, loss: 1.9138439893722534\n",
      "Epoch 19, iter 770, loss: 0.8580442070960999\n",
      "Epoch 19, iter 780, loss: 0.7416619658470154\n",
      "Epoch 19, iter 790, loss: 0.65770024061203\n",
      "Epoch 19, iter 800, loss: 14.660964012145996\n",
      "Epoch 19, iter 810, loss: 1.498117446899414\n",
      "Epoch 19, iter 820, loss: 7.920175075531006\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs=20\n",
    "for epoch in range(epochs):\n",
    "    for i, (imgs,kps) in enumerate(train_loader):\n",
    "        imgs = imgs.to(device)\n",
    "        kps = kps.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, kps)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, iter {i}, loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"keypoints_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
